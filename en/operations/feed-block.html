---
# Copyright Vespa.ai. All rights reserved.
title: "Feed block"
---

<p>
  A content cluster blocks external write operations when at least one content node has reached the
  <a href="../reference/services-content.html#resource-limits">resource limit</a>
  of disk or memory. This is done to avoid saturating resource usage on content nodes.
  The <em>Cluster controller</em> monitors the resource usage of the content nodes
  and decides whether to block feeding.
  Transient resource usage (see details in the metrics below) is not included in the monitored usage.
  This ensures that transient resource usage is covered by the resource headroom on the content nodes,
  instead of leading to feed blocked due to natural fluctuations.
</p>
{% include note.html content="When running Vespa in a Docker image on a laptop,
one can easily get <code>[UNKNOWN(251009) @ tcp/vespa-host:19112/default]:
ReturnCode(NO_SPACE, External feed is blocked due to resource exhaustion:
in content cluster 'example': disk on node 0 [vespa-host] is 76.7% full (the configured limit is 75.0%,
effective limit lowered to 74.0% until feed unblocked)</code>.
Fix this by increasing allocated storage for the Docker daemon, clean up unused volumes
or remove unused Docker images." %}
<p>HTTP clients will see <em>507 Server Error: Insufficient Storage</em> when this happens.</p>
<p>
  When feed is blocked, write operations are rejected by <em>Distributors</em>.
  All Put operations and most Update operations are rejected.
  These operations are still allowed:
</p>
<ul>
  <li>Remove operations</li>
  <li>Update <a href="../reference/document-json-format.html#assign">assign</a> operations to numeric single-value fields</li>
</ul>
<p>
  To remedy, add nodes to the content cluster.
  The data will <a href="../elasticity.html">auto-redistribute</a>, and feeding is unblocked when
  all content nodes are below the limits.
  For self-managed Vespa you can configure <a href="../reference/services-content.html#resource-limits">resource-limits</a>,
  although this is not recommended. Increasing them too much might lead to OOM and content nodes being unable to start.
</p>
{% include important.html content="Always <strong>add</strong> nodes, do not change node capacity -
this is in practise safer and quicker.
As most Vespa applications are set up on homogeneous nodes, changing node capacity can cause a full node set swap
and more data copying than just adding more nodes of the same kind.
Copying data will in itself stress nodes, adding one node is normally the smallest and safest change."%}
<p>
  These <a href="metrics.html">metrics</a> are used to monitor resource usage and whether feeding is blocked:
</p>
<table class="table">
  <tr>
    <th>cluster-controller.resource_usage.nodes_above_limit</th>
    <td>The number of content nodes that are above one or more resource limits. When above 0, feeding is blocked.</td>
  </tr>
  <tr>
    <th>content.proton.resource_usage.disk</th>
    <td>A number between 0 and 1, indicating how much disk (of total available) is used on the content node.
    Transient disk used during <a href="../proton.html#disk-index-fusion">disk index fusion</a> is not included.</td>
  </tr>
  <tr>
    <th>content.proton.resource_usage.memory</th>
    <td>A number between 0 and 1, indicating how much memory (of total available) is used on the content node.
    Transient memory used by <a href="../proton.html#memory-index-flush">memory indexes</a> is not included.</td>
  </tr>
</table>
<p>
When feeding is blocked, error messages are returned in write operation replies - example:
</p>
<pre>
ReturnCode(NO_SPACE, External feed is blocked due to resource exhaustion:
                     in content cluster 'example': memory on node 0 [my-vespa-node-0.example.com] is 82.0% full (the configured limit is 80.0%, effective limit lowered to 79.0% until feed unblocked))
</pre>
<p>
  Note that when feeding is blocked resource usage needs to decrease below another, lower limit before getting unblocked. This is to avoid
  flip-flopping between blocking and unblocking feed when being near the limit. This lower limit is 1% lower than the configured limit.
</p>

<p>
  The address space used by data structures in attributes (<em>Multivalue Mapping</em>, <em>Enum Store</em>, and <em>Tensor Store</em>) can also go full and block feeding -
  see <a href="../attributes.html#data-structures">attribute data structures</a> for details.
  This will rarely happen.
  The following metric is used to monitor address space usage:
</p>
<table class="table">
  <tr>
    <th>content.proton.documentdb.attribute.resource_usage.address_space.max</th>
    <td>A number between 0 and 1, indicating how much address space is used by the worst attribute data structure on the content node.</td>
  </tr>
</table>
<p>
  An error is returned when the address space limit (default value is 0.90) is exceeded:
</p>
<pre>
ReturnCode(NO_SPACE, External feed is blocked due to resource exhaustion:
                     in content cluster 'example': attribute-address-space:example.ready.a1.enum-store on node 0 [my-vespa-node-0.example.com] is 91.0% full (the configured limit is 90.0%))
</pre>
<p>
To remedy, add nodes to the content cluster to distribute documents with attributes over more nodes.
</p>
