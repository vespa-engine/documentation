---
# Copyright Vespa.ai. All rights reserved.
title: "Ranking"
---

<p>
  Vespa ranks documents retrieved by a query by performing computations or inference that produces a score for each document. 
  The documents are sorted in descending order by this score, and highest ranking documents are returned to the user. Ranking
  is useful in search and recommendation systems, where the goal is to present the most relevant results to the user.
</p>
<p>
  Ranking in Vespa is configured using 
  declarative <a href="ranking-expressions-features.html">ranking expressions</a>, 
  These expressions vary from basic mathematical operations with <a href="reference/rank-features.html">rank features</a> to
  more complex <a href="tensor-examples.html">tensor expressions</a> or 
  machine-learned models. These ranking expressions are configured in <a href="#rank-profiles">rank profiles</a> within document <a href="schemas.html">schemas</a>.
</p>

<h2 id="retrieval-versus-ranking">Retrieval versus ranking</h2>
<p>To understand the difference between retrieval (matching) and ranking, consider the 
  following text-search oriented Vespa query example,
  expressed in JSON POST format using Vespa's <a href="query-language.html">query language</a>:</p>
<pre>
  {
    "yql": "select * from doc where text contains \"vespa\"",
    "ranking": {
      "profile": "my-rank-profile"
    },
    "inputs": {
      "query(user_context)":Â [0.1, 0.2, 0.3]
    }
  }
  </pre>
<p>
  The <code>yql</code> part of the query specifies the retrieval part, which retrieves documents that contain the word "vespa".
  The <code>ranking</code> part specifies the ranking profile to use when <strong>ranking</strong> the retrieved documents. 
  This profile defines how to compute the score for each document retrieved by the query.
</p>

<pre>
  rank-profile my-rank-profile inherits default {
    inputs {
      query(user_context) tensor&lt;float&gt;(x[3])
    }
    first-phase {
      expression: bm25(text) + sum(query(user_context) * attribute(document_context))
    }
  }
</pre>
<p>
  The <code>first-phase</code> part of the rank profile specifies the ranking expression to use when scoring
  the retrieved documents. In this example, the expression is a combination of the <a href="reference/bm25.html">BM25</a> 
  text matching feature and a dot product between the query and document context tensors using 
  Vespa <a href="tensor-user-guide.html#ranking-with-tensors">tensor computations</a>. </p>

<p>
  Since the query matched against the <em>text</em> field, Vespa can calculate text matching 
  rank features, such as <a href="reference/bm25.html">bm25</a>. 
</p>

<p>
  The <code>query(user_context)</code> tensor is another feature that is passed with the query request, but does
  not match against any field in the document. Instead, it is used to compute a score based on the dot product
  with the <code>document_context</code> attribute. This is an example of how Vespa can use additional
  features in ranking, even if they do not match against any field in the document.
</p>

<h2 id="phased-ranking">Phased ranking</h2>

<p>Rank profiles can define multiple <a href="phased-ranking.html">ranking phases</a>, where you can define different ranking expressions
  that are applied in sequence. This is useful for separating the ranking logic into multiple steps
  where the first phase is executed for all retrieved documents and the second-phase is executed for the top-scoring
  documents from the first-phase. This can be used to direct more computation towards the most promising candidate documents.

<pre>
schema myapp {

    rank-profile my-rank-profile {

        first-phase {
            expression {
                attribute(quality) * freshness(timestamp) + bm25(title)
            }
        }
        second-phase {
            expression: sum(onnx(my_onnx_model))
            rerank-count: 50
        }
        global-phase {
          expression: sum(onnx(my_larger_onnx_model))
          rerank-count: 20
      }

    }
}
</pre>

<h2 id="machine-learned-model-inference">Machine-Learned model inference</h2>

<p>To achieve better ranking accuracy, most organizations turn to machine learned ranking. 
  Vespa supports importing ML models in these formats:</p>

<ul>
    <li><a href="onnx.html">ONNX</a>, allowing importing models from popular ML frameworks like Tensorflow, PyTorch and scikit-learn.</li>
    <li><a href="xgboost.html">XGBoost</a></li>
    <li><a href="lightgbm.html">LightGBM</a></li>
</ul>

<p>As these are exposed as rank features, it is possible to rank documents using a <em>model ensemble</em>, or unify 
  models from different frameworks in a single rank-profile. 
  Models are deployed in <a href="applications.html">application packages</a> or downloaded from urls.
</p>

<!-- ToDo: Not exclusive list, we can represent lots of model, logistic regression etc. Also mention PyTorch through ONNX. -->

<h2 id="rank-profiles">Rank profiles</h2>
<p>Ranking expressions are defined in <a href="reference/schema-reference.html#rank-profile">rank profiles</a> -
either inside the schema or equivalently in their own files in the
<a href="reference/application-packages-reference.html">application package</a>, named
<code>schemas/[schema-name]/[profile-name].profile</code>.</p>

<p>One schema can have any number of rank profiles for implementing e.g. different use cases
or <a href="testing.html#feature-switches-and-bucket-tests">bucket testing</a> variations.
If no profile is specified in the schema, the <a href="nativerank.html">default (nativeRank)</a>
profile is used.</p>

<p>Rank profiles can <em>inherit</em> other profiles. This makes it possible to define complex profiles and variants
without duplication.</p>

<p>Queries select a rank profile using the
<a href="reference/query-api-reference.html#ranking.profile">ranking.profile</a> argument
in requests or a <a href="query-profiles.html">query profiles</a>,
or equivalently in <a href="searcher-development.html">Searcher</a> code, by</p>

<pre>
query.getRanking().setProfile("my-rank-profile");
</pre>

<p>If no profile is specified in the query, the one called <code>default</code> is used.
This profile is available also if not defined explicitly. The default rank-profile uses <a href="nativerank.html">nativeRank</a>
which is a text-scoring only feature. Another built-in rank profile <code>unranked</code> is also always available.
Specifying this boosts serving performance in queries which do not need ranking because ordering is not important or
<a href="reference/sorting.html">explicit field sorting</a> is used.</p>

