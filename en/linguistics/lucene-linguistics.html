---
# Copyright Vespa.ai. All rights reserved.
title: "Lucene Linguistics"
redirect_from:
- /en/lucene-linguistics.html
---

<p>
  Lucene Linguistics is a custom <a href="linguistics.html">linguistics</a> implementation of the
  <a href="https://lucene.apache.org">Apache Lucene</a> library.
  It provides a Lucene analyzer to handle text processing for a language
  with an optional variation per <a href="https://github.com/vespa-engine/vespa/blob/master/linguistics/src/main/java/com/yahoo/language/process/StemMode.java">stemming mode</a>.
</p>

<p>
  Check <a href="https://github.com/vespa-engine/sample-apps/tree/master/examples/lucene-linguistics">sample apps</a> to
  get started.
</p>

<h2 id="crash-course-to-lucene-text-analysis">Crash course to Lucene text analysis</h2>

<p>
  Lucene <a href="https://lucene.apache.org/core/9_8_0/core/org/apache/lucene/analysis/package-summary.html">text
  analysis</a>
  is a process of converting text into searchable tokens.
  This text analysis consists of a series of components applied to the text in order:
</p>
<ul>
  <li>
    <a href="https://lucene.apache.org/core/9_8_0/core/org/apache/lucene/analysis/CharFilter.html">CharFilters</a>:
    transform the text before it is tokenized, while providing corrected character offsets to account for these
    modifications.
  </li>
  <li><a href="https://lucene.apache.org/core/9_8_0/core/org/apache/lucene/analysis/Tokenizer.html">Tokenizers</a>:
    responsible for breaking up incoming text into tokens.
  </li>
  <li>
    <a href="https://lucene.apache.org/core/9_8_0/core/org/apache/lucene/analysis/TokenFilter.html">TokenFilters</a>:
    responsible for modifying tokens that have been created by the Tokenizer.
  </li>
</ul>

<p>
  A specific configuration of the above components is wrapped into an
  <a href="https://lucene.apache.org/core/9_8_0/core/org/apache/lucene/analysis/Analyzer.html">Analyzer</a> object.
</p>

The text analysis works as follows:
<ol>
  <li>All char filters are applied in the specified order on the entire text string</li>
  <li>Token filters in the specified order are applied on each token.</li>
</ol>

<h2 id="defaults-language-analysis">Defaults language analysis</h2>

<p>
  Lucene Linguistics out-of-the-box exposes the analysis components provided
  by the <a href="https://lucene.apache.org/core/9_8_0/core/index.html">lucene-core</a>
  and the
  <a href="https://lucene.apache.org/core/9_8_0/analysis/common/index.html">lucene-analysis-common</a>
  libraries.
  Other libraries with Lucene text analysis components
  (e.g. <a href="https://lucene.apache.org/core/9_8_0/analysis/kuromoji/index.html">analysis-kuromoji</a>)
  can be added to the application package as a Maven dependency.
</p>

<p>
  Lucene Linguistics out-of-the-box provides analyzers for 40 languages:
</p>
<ul>
  <li>Arabic</li>
  <li>Armenian</li>
  <li>Basque</li>
  <li>Bengali</li>
  <li>Bulgarian</li>
  <li>Catalan</li>
  <li>Chinese</li>
  <li>Czech</li>
  <li>Danish</li>
  <li>Dutch</li>
  <li>English</li>
  <li>Estonian</li>
  <li>Finnish</li>
  <li>French</li>
  <li>Galician</li>
  <li>German</li>
  <li>Greek</li>
  <li>Hindi</li>
  <li>Hungarian</li>
  <li>Indonesian</li>
  <li>Irish</li>
  <li>Italian</li>
  <li>Japanese</li>
  <li>Korean</li>
  <li>Kurdish</li>
  <li>Latvian</li>
  <li>Lithuanian</li>
  <li>Nepali</li>
  <li>Norwegian</li>
  <li>Persian</li>
  <li>Portuguese</li>
  <li>Romanian</li>
  <li>Russian</li>
  <li>Serbian</li>
  <li>Spanish</li>
  <li>Swedish</li>
  <li>Tamil</li>
  <li>Telugu</li>
  <li>Thai</li>
  <li>Turkish</li>
</ul>

<p>
  The Lucene
  <a href="https://lucene.apache.org/core/9_8_0/core/org/apache/lucene/analysis/standard/StandardAnalyzer.html">StandardAnalyzer</a>
  is used for the languages that doesn't have a custom nor a default analyzer.
</p>

<h2 id="linguistics-key">Linguistics key</h2>

<p>
  Linguistics keys identify a configuration of text analysis. It can be made of two parts,
  separated by a semicolon, though you can omit one or the other. The two parts are:
  <ul>
    <li>
      A <a href="linguistics.html#linguistics-profiles">linguistics profile</a>.
    </li>
    <li>
      A language key.
    </li>
  </ul>
</p>
<p>
  The language key, in turn, has 2 parts: a mandatory <a href="https://github.com/vespa-engine/vespa/blob/master/linguistics/src/main/java/com/yahoo/language/Language.java">
  language code</a> and an optional stemming mode.
  The format is <code>LANGUAGE_CODE[/STEM_MODE]</code>.
  There are 5 stemming modes: <code>NONE, DEFAULT, ALL, SHORTEST, BEST</code> (they can be specified in the <a href="../reference/schemas/schemas.html#stemming">field schema</a>).
</p>

<p>Examples of linguistics key:</p>
<ul>
  <li>
    <code>profile=whitespaceLowercase</code>: a profile that applies to all languages. You can bind it to
    different fields by specifying their <a href="linguistics.html#linguistics-profiles">linguistics profiles</a> in the schema.
  </li>
  <li>
    <code>profile=whitespaceLowercase;language=en</code>: a profile that applies to the English language.
    You'd still bind it to fields via their <a href="linguistics.html#linguistics-profiles">linguistics profiles</a> in the schema,
    but it will only be applied to the English texts (either at indexing or query time).
  </li>
  <li>
    <code>en</code>: English language: applies to all English texts where no profile is specified
    (in the schema or <a href="linguistics.html#overriding-profile-for-query-strings">in the query</a>).
  </li>
  <li>
    <code>en/BEST</code>: English language with the <code>BEST</code> stemming mode. Like the previous example,
    but only applies when <a href="../reference/schemas/schemas.html#stemming">stemming</a> is set to <code>BEST</code>.
  </li>
</ul>

{% include note.html content='You can use different profiles for document fields and query strings.
See <a href="linguistics.html#different-processing-for-query-strings">Different processing for query strings</a> and the
<a href="https://github.com/vespa-engine/sample-apps/tree/master/examples/lucene-linguistics/multiple-profiles">multiple-profiles sample app</a> for more information.' %}

<h2 id="custom-analysis">Customizing text analysis</h2>

<p>
  Lucene linguistics provides multiple ways to customize text analysis per language:
</p>
<ul>
  <li>
    <code>LuceneLinguistics</code> component configuration in the <code>services.xml</code>
  </li>
  <li>
    <code>ComponentsRegistry</code>
  </li>
</ul>

<h3 id="lucene-linguistics-configuration">LuceneLinguistics component configuration</h3>

<p>
  In <code>services.xml</code> it is possible to construct an analyzer by providing
  <a href="https://github.com/vespa-engine/vespa/blob/master/lucene-linguistics/src/main/resources/configdefinitions/lucene-analysis.def">configuration for the</a>
  <code>LuceneLinguistics</code> component (from all text analysis components that are available on the classpath).
  Example for the English language:
</p>

<pre>{% highlight xml %}
  <component id="linguistics"
             class="com.yahoo.language.lucene.LuceneLinguistics"
             bundle="your-bundle-name">
    <config name="com.yahoo.language.lucene.lucene-analysis">
      <configDir>lucene-linguistics</configDir>
      <analysis>
        <item key="profile=standardStopStem;language=en">
          <tokenizer>
            <name>standard</name>
          </tokenizer>
          <tokenFilters>
            <item>
              <name>stop</name>
              <conf>
                <item key="words">en/stopwords.txt</item>
                <item key="ignoreCase">true</item>
              </conf>
            </item>
            <item>
              <name>englishMinimalStem</name>
            </item>
          </tokenFilters>
        </item>
      </analysis>
    </config>
  </component>
{% endhighlight %}</pre>

<p>Notes:</p>
<ul>
  <li>
    <code>item key="profile=standardStopStem;language=en"</code> value is a <a href="#linguistics-key">linguistics key</a>.
  </li>
  <li>
    <code>name</code> values are the <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.naming/javax/naming/spi/package-summary.html">SPI names</a>
    of the text analysis components. You'll typically find them in the
    <a href="https://lucene.apache.org/core/9_11_1/analysis/common/allclasses-index.html">Lucene analysis JavaDocs</a>.
    For example, the name <code>stop</code> along with other options can be found in the
    <a href="https://lucene.apache.org/core/9_11_1/analysis/common/org/apache/lucene/analysis/core/StopFilterFactory.html">StopFilterFactory JavaDoc</a>.
  </li>
  <li>
    The <code>en/stopwords.txt</code> file must be placed in your application package under
    the <code>lucene-linguistics</code> directory, which is referenced by the <code>configDir</code> option.
  </li>
  <li>
    If <code>configDir</code> is not provided the files must be on the classpath.
  </li>
</ul>

<h3 id="components-registry">Components registry</h3>

<p>
  The <a href="../applications/dependency-injection.html#depending-on-all-components-of-a-specific-type">ComponentsRegistry</a>
  mechanism can be used to set a Lucene Analyzer for a language.
</p>

<p>
</p>

<pre>{% highlight xml %}
<component
    id="en"
    class="org.apache.lucene.analysis.core.SimpleAnalyzer"
    bundle="your-bundle-name" />
{% endhighlight %}</pre>

<p>
  Where:
</p>
<ul>
  <li>
    <code>id</code> must be a <a href="#linguistics-key">linguistics key</a>;
  </li>
  <li>
    <code>class</code> is the implementation class that extends the `Analyzer` class;
  </li>
  <li>
    <code>bundle</code> is a name of the application package as specified in the <code>pom.xml</code>
    (or can be any bundle added to your <code>components</code> dir that contains the class).
  </li>
</ul>

<p>
  For this to work, the class must provide <b>only</b> a constructor without arguments.
</p>

<p>
  In case your analyzer class needs some initialization you must wrap the analyzer into a class
  that implements the <code>Provider&lt;Analyzer&gt;</code> class.
</p>

<h3 id="adding-custom-analysis-component">Custom text analysis components</h3>

<p>
  The text analysis components are loaded via Java Service provider interface (<a
    href="https://www.baeldung.com/java-spi" data-proofer-ignore>SPI</a>).
</p>

<p>
  To use an external library that is properly prepared it is enough to add the
  library to the application package as a Maven dependency.
</p>

<p>
  In case you need to create a custom component the steps are:
</p>
<ol>
  <li>Implement a component in a Java class</li>
  <li>Register the component class in the (e.g. a custom token filter) <code>META-INF/services/org.apache.lucene.analysis.TokenFilterFactory</code>
    file that is on the classpath.
  </li>
</ol>

<h2 id="language-detection">Language Detection</h2>

<p>
  Lucene Linguistics doesn't provide language detection.
  This means that for both feeding and searching you should provide a
  <a href="../reference/api/query.html#model.language">language parameter</a>.
</p>

<h2 id="troubleshooting-lucene-text-analysis">Troubleshooting Lucene text analysis</h2>

<p>
  If your documents don't match as expected, there are two ways to get more information.

  First, you can get the tokenized text for a field by using <a href="../reference/schemas/schemas.html#tokens">tokens</a>
  in the <a href="../querying/document-summaries.html">document summary</a>.
  For example, to get the original text and tokens for the <code>title</code> field:
</p>

<pre>
  document-summary debug-text-tokens {
    summary title {}
    summary title_tokens {
        source: title
        tokens
    }
    from-disk
}
</pre>

<p>
  Then, at query time, you can also get the tokens of the query string
  by increasing the <a href="../reference/api/query.html#trace.level">trace level</a>:
</p>

<pre>{% highlight json %}
{
  "yql": "select * from sources * where title contains \"dog\"",
  "presentation.summary": "debug-text-tokens",
  "model.locale": "en",
  "trace.level": 2
}
{% endhighlight %}</pre>

<h3 id="indexing-all-stemmed-words">Indexing all stems</h3>

<p>
  Some analyzers expand the input text into multiple tokens on the same position.
  For example, those based on the <a href="https://lucene.apache.org/core/9_11_1/analysis/common/org/apache/lucene/analysis/ngram/NGramTokenFilter.html">NGramTokenFilter</a>.
  Here's a sample analyzer configuration:
</p>

<pre>{% highlight xml %}
<item key="profile=ngram;language=en">
  <tokenizer>
    <name>whitespace</name>
  </tokenizer>
  <tokenFilters>
    <item>
      <name>nGram</name>
      <conf>
        <item key="minGramSize">2</item>
        <item key="maxGramSize">2</item>
      </conf>
    </item>
  </tokenFilters>
</item>
{% endhighlight %}</pre>

<p>
  This will take a text like <code>dog</code> and produce <code>do</code> and <code>og</code> as tokens, plus (by default) the original <code>dog</code>.
  However, Vespa only takes the first token (<code>do</code>) and writes it to the index, ignoring the other "stems". As a result,
  a search for <code>og</code> will not match documents that contain <code>dog</code>, which is the whole point of using letter n-grams.
</p>

<p>
  To index all stems, you can use the <a href="../reference/schemas/schemas.html#stemming">stemming</a> parameter in the schema definition of your field:
</p>

<pre>
field title_grams type string {
  indexing: summary | index
  linguistics {
      profile: ngram
  }
  stemming: multiple
}
</pre>

<p>
  Now, Vespa will index all stems, and a search for <code>og</code> will match documents that contain <code>dog</code>.
</p>

{% include note.html content='Queries look for all stems by default (regardless of the schema configuration). For example, a search for
<code>dog</code> would expand to <code>do</code> and <code>og</code> as well, looking for all three terms.' %}