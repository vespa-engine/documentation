---
# Copyright Vespa.ai. All rights reserved.
title: "Linguistics in Vespa"
redirect_from:
- /en/linguistics.html
---

<p>
  Vespa uses a <em>linguistics</em> module to process text in queries and documents during indexing and searching.
  The goal of linguistic processing is to increase <em>recall</em> (how many documents are matched)
  without hurting <em>precision</em> (the relevance of the documents matched) too much.
  It consists of such operations as:
</p>
<ul>
  <li>tokenizing text into chunks of known types such as words and punctuation.</li>
  <li>normalizing accents.</li>
  <li>finding the base form of words (stemming or lemmatization).</li>
</ul>
<p>
  Linguistic processing is run when writing documents, and when querying:
</p>
<img src="/assets/img/vespa-overview-linguistics.svg" alt="Overview: linguistic processing in Vespa"
     width="810px" height="auto" />
<p>
  The processing is run on <a href="../reference/schemas/schemas.html#string">string</a> fields
  with <code>index</code> indexing mode. Overview:
</p>
<ol>
  <li>
    When writing documents, string fields with <code>indexing: index</code> are by default processed.
    A field's language will configure this processing.
    A document/fields can have the language set explicitly,
    if not, it is <a href="#field-language-detection">detected</a>.
    <!-- ToDo: link to detector / info here -->
  </li>
  <li>
    The field's content is processed (e.g., tokenized, normalized, stemmed, etc.),
    and the resulting terms are added to the index.
    {% include note.html content='The language for the field is not persisted on the content node,
    just the processed terms themselves' %}
  </li>
  <li>
    A query is also processed in a similar fashion. Typically through the same 
    <a href="../reference/schemas/schemas.html#linguistics">linguistics profile</a> as the field content,
    producing the same terms from the same text.
    The language of query strings is <a href="#query-language-detection">detected</a> unless specified using
    <a href="../reference/api/query.html#model.locale">model.locale</a>
    or <a href="../reference/querying/yql.html#annotations">annotations</a> like <code>language</code>.
    {% include note.html content='This is a very common query problem -
    it is hard to detect language precisely from short strings.' %}
  </li>
  <li>
    The processed query is evaluated on the content nodes,
    and will only work as expected if both documents and queries produce the same terms.
  </li>
</ol>
<p>
  These operations can be turned on or off per field in the <a href="../basics/schemas.html">schema</a>.
  See <a href="../reference/querying/yql.html#implicittransforms">implicitTransforms</a>
  for how to enable/disable transforms per query term.
</p>

<h2 id="linguistics-implementations">Linguistics implementations</h2>
<p>
  Vespa comes with two linguistics variants out of the box:
  <a href="linguistics-opennlp.html">OpenNLP</a> and <a href="lucene-linguistics.html">Lucene</a>.
  Check out the respective pages for more information on how to configure them.
</p>
<p>
  You can also implement a custom <a href="linguistics-custom.html">Linguistics</a> component.
</p>
<p>
  The default linguistics variant is <a href="linguistics-opennlp.html">OpenNLP</a>, but for the
  rest of this page we'll go through common options, such as language handling, inherited by
  all implementations.
</p>

{% include note.html content='Linguistics implementations only control how text is tokenized,
  including positional information. These tokens are stored in the same way in the underlying
  index. For example, if you use Lucene linguistics, Vespa does not store information such as
  positions in Lucene segment files. Storage is the same as with OpenNLP,
  only resulting tokens might differ.' %}

<h2 id="language-handling">Language handling</h2>
<p>
Vespa does <em>not</em> know the language of a document - this applies:
</p>
<ol>
  <li>The indexing processor is instructed on a per-field level what language to
use when calling the underlying linguistics library</li>
  <li>The query processor is instructed on a per-query level what language to use</li>
</ol>
<p>
If no language is explicitly set in a document or a query,
Vespa will run its configured language detector (by default, <a href="linguistics-opennlp.html#language-detection">OpenNLP language detection</a>)
on the available text (the full content of a document field, or the full <code>query=</code> parameter value).
</p><p>
A document that contains the exact same word as a query might not be recall-able
if the language of the document field is detected differently from the query.
Unless the query has explicitly declared a <a href="../reference/api/query.html#model.language">language</a>,
this can occur.
</p>


<h3 id="indexing-with-language">Indexing with language</h3>

<p>The indexing process run by Vespa is a sequential execution
of the indexing scripts of each field in the schema, in the declared order.
At any point, the script may set the language that will be used for indexing statements for subsequent fields,
using <a href="../reference/writing/indexing-language.html#set_language">set_language</a>.

Example:
</p>
<pre>
schema doc {
    document doc {
        field language type string {
            indexing: set_language
        }
        field title type string {
            indexing: index
        }
    }
}
</pre>

<p>If a language has not been set when tokenization of a field is run, the language is determined by
<a href="#field-language-detection">language detection</a>.</p>

<p>If all documents have the same language, the language can be hardcoded it the schema in this way:</p>
<pre>
schema doc {

    field language type string {
        indexing: "en" | set_language
    }

    document doc {
    ...
</pre>
<p>If the same document contains fields in multiple languages, set_language can be invoked multiple times, e.g.:</p>
<pre>
schema doc {
    document doc {
        field language_title1 type string {
            indexing: set_language
        }
        field title1 type string {
            indexing: index
        }
        field language_title2 type string {
            indexing: set_language
        }
        field title2 type string {
            indexing: index
        }
    }
}
</pre>

<p>Or, if fixed per field, use multiple indexing statements in each field:</p>

<pre>
schema doc {
    document doc {
        field my_english_field type string {
            indexing {
                "en" | set_language;
                index;
            }
        }
        field my_spanish_field type string {
            indexing {
                "es" | set_language;
                index;
            }
        }
    }
}
</pre>


<h3 id="field-language-detection">Field language detection</h3>
<p>
  When indexing a document, if a field has unknown language (i.e. not set using <code>set_language</code>),
  language detection is run on the field's content.
  This means, language detection is per field, not per document.
</p>
<p>
  See <a href="#query-language-detection">query language detection</a> for detection confidence,
  fields with little text will default to English.
</p>


<h3 id="querying-with-language">Querying with language</h3>
<p>
  The content of an indexed string field is language-agnostic.
  One must therefore apply a compatible tokenization on the query terms (e.g., stemming for the same language)
  in order to match the content of that field.
</p>
<p>
  The query parser subscribes to configuration that tells it what fields are indexed strings,
  and every query term that targets such a field are run through appropriate tokenization.
  The <a href="../reference/api/query.html#model.language">language</a> query parameter
  controls the language state of these calls.
</p>
<p>
  Because an index may simultaneously contain terms in any number of languages,
  one can have stemmed variants of one language match the stemmed variants of another.
  To work around this, store the language of a document in a separate attribute,
  and apply a filter against that attribute at query-time.
</p>
<p>
  By default, there is no knowledge anywhere that captures what
  languages are used to generate the content of an index.
  The language parameter only affects the transformation of query terms that hit tokenized indexes.
</p>


<h3 id="query-language-detection">Query language detection</h3>
<p>
  If no <a href="../reference/api/query.html#model.language">language</a> parameter is used,
  or the query terms are <a href="../reference/querying/yql.html#annotations">annotated</a>,
  the language detector is called to process the query string.
</p>
<p>
  Queries are normally short, as a consequence, the detection confidence is low. Example:
</p>
<pre>
$ vespa query "select * from music where userInput(@text)" \
  tracelevel=3 text='Eine kleine Nachtmusik' | grep 'Stemming with language'
    "message": "Stemming with language=ENGLISH"

$ vespa query "select * from music where userInput(@text)" \
  tracelevel=3 text='Eine kleine Nachtmusik schnell' | grep 'Stemming with language'
    "message": "Stemming with language=GERMAN"
</pre>
<p>
  See <a href="https://github.com/vespa-engine/vespa/issues/24265">#24265</a> for details -
  in short, with the current 0.02 confidence cutoff, queries with 3 terms or fewer will default to English.
</p>


<h3 id="multiple-languages">Multiple languages</h3>
<p>Vespa supports having documents in multiple languages in the same schema, but does not out-of-the-box 
  support cross-lingual retrieval (e.g., search using English and retrieve relevant documents written in German). 
  
  This is because the language of a query is determined 
  by the language of the query string and only one transformation can take place. 
</p>
<p>
Approaches to overcome this limitation include:
</p>
<ol>
    <li>
        Use semantic retrieval using a multilingual text embedding model (see <a href="https://blog.vespa.ai/simplify-search-with-multilingual-embeddings/">blog post</a>) 
        which has been trained on multilingual corpus and can be used to retrieve documents in multiple languages.
    </li><li>
        Stem and tokenize the query using the relevant languages,
        build a query tree using <a href="../reference/querying/yql.html#weakand">weakAnd</a> /
        <a href="../reference/querying/yql.html#or">or</a>
        and using <a href="../reference/querying/yql.html#equiv">equiv</a> per stem variant.
        This is easiest done in a custom <a href="../applications/searchers.html">Searcher</a> as mentioned in
        <a href="https://github.com/vespa-engine/vespa/issues/12154">#12154</a>.
    </li>
</ol>
<p>
Example:
</p><p>
<strong>language=fr:</strong> machine learning =&gt; machin learn
</p><p>
<strong>language=en:</strong> machine learning =&gt; machine learn
</p><p>
Using <em>weakAnd</em> here as example as that technique is already mentioned in #12154:
</p>
<pre>
select * from sources * where rank( 
    default contains "machine", 
    default contains "learning",
    weakAnd(
      default contains equiv("machin", "machine"), 
      default contains "learn"
    )
)
</pre>
<p>
We now retrieve using all possible stems/base forms with <em>weakAnd</em>,
and use the <a href="../reference/querying/yql.html#rank">rank</a> operator
to pass in the original query form, so that ranking can rank literal matches (original) higher.
Benefit of <em>equiv</em> is that it allows multiple term variants to share the same position,
so that proximity ranking does not become broken by this approach.
</p>

<h2 id="linguistics-profiles">Linguistics profiles</h2>

<p>
  <a href="../reference/schemas/schemas.html#linguistics"></a>Linguistics profiles</a> are used
  to configure linguistics processing for a field in the schema. They are typically used with
  the <a href="lucene-linguistics.html">Lucene linguistics implementation</a>, but can be used
  in e.g., <a href="linguistics-custom.html">custom linguistics implementations</a> as well.
</p>

<h3 id="symmetrical-processing">Symmetrical processing</h3>

<p>
  For example, a definition like this:
</p>
<pre>
field title type string {
  indexing: summary | index
  linguistics {
      profile: whitespaceLowercase
  }
}
</pre>

<p>
  Will look for a profile named <code>whitespaceLowercase</code>, which could be defined like this
  in <code>services.xml</code>:
</p>
<pre>{% highlight xml %}
  <item key="profile=whitespaceLowercase;language=en">
    <tokenizer>
      <name>whitespace</name>
    </tokenizer>
    <tokenFilters>
      <item>
        <name>lowercase</name>
      </item>
    </tokenFilters>
  </item>
{% endhighlight %}</pre>

<p>
  Note <code>language=en</code> there. It is optional: if it's not set,
  the profile will be used for all languages. But you can have different
  definitions for different languages on the same profile (e.g., different stemming).
</p>

<h3 id="different-processing-for-query-strings">Different processing for query strings</h3>

<p>
  For some use cases, you may want to process the query string differently than the document content.
  Synonyms are a good example. If you expand <code>dog</code> to <code>dog,puppy</code> at query time,
  it will match either term in the document anyway - no need to expand it at write-time.
</p>

<p>
  To do this, you'd define a different profile for the query string. Like:
</p>
<pre>{% highlight xml %}
  <item key="profile=whitespaceLowercaseSynonyms;language=en">
    <tokenizer>
      <name>whitespace</name>
    </tokenizer>
    <tokenFilters>
      <item>
        <name>lowercase</name>
      </item>
      <item>
        <name>synonymGraph</name>
        <conf>
          <!--
            Synonyms file should contain something like:
            dog,puppy
          -->
          <item key="synonyms">en/synonyms.txt</item>
        </conf>
      </item>
    </tokenFilters>
  </item>
{% endhighlight %}</pre>

<p>
  Then, in the schema, expand <code>profile</code> to <code>profile.index</code> and <code>profile.search</code>:
</p>

<pre>
  field title type string {
    indexing: summary | index
    linguistics {
        profile {
            index: whitespaceLowercase
            search: whitespaceLowercaseSynonyms
        }
    }
}
</pre>

<p>
  At this point, <code>where synonyms_test contains 'dog'</code> will match a document containing <code>puppy</code>.
</p>

<h3 id="overriding-profile-for-query-strings">Overriding profile for query strings</h3>

<p>
  At query time, you can force Vespa to use a specific profile to process the query string via <a href="../reference/querying/yql.html#grammar">grammar.profile</a>.
  This works with <a href="../reference/querying/yql.html#userinput">userInput()</a> or <a href="../reference/querying/yql.html#text">text()</a> operators.
  For example, to use the <code>whitespaceLowercase</code> profile for the query string:
</p>

<pre>
where title contains ({grammar.profile: 'whitespaceLowercase'}text('dog'))
</pre>

Equivalent expression via <code>userInput()</code>:
<pre>
where {defaultIndex:'title', grammar.profile: 'whitespaceLowercase', grammar: 'linguistics'}userInput('dog')
</pre>

{% include note.html content='You should use grammar=linguistics (like in the example above) with grammar.profile to ensure that there is no
additional processing (e.g., tokenization) besides what is already defined in the profile.' %}


<h2 id="troubleshooting-linguistics-processing">Troubleshooting linguistics processing</h2>

<p>
  If your documents don't match as expected, there are two ways to get more information.

  First, you can get the tokenized text for a field by using <a href="../reference/schemas/schemas.html#tokens">tokens</a>
  in the <a href="../querying/document-summaries.html">document summary</a>.
  For example, to get the original text and tokens for the <code>title</code> field:
</p>

<pre>
  document-summary debug-text-tokens {
    summary title {}
    summary title_tokens {
        source: title
        tokens
    }
    from-disk
}
</pre>

<p>
  Then, at query time, you can also get the tokens of the query string
  by increasing the <a href="../reference/api/query.html#trace.level">trace level</a>:
</p>

<pre>{% highlight json %}
{
  "yql": "select * from sources * where title contains \"dog\"",
  "presentation.summary": "debug-text-tokens",
  "model.locale": "en",
  "trace.level": 2
}
{% endhighlight %}</pre>