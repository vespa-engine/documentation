---
# Copyright Vespa.ai. All rights reserved.
title: "Tutorials and use cases"
redirect_from:
- /en/vespa-quick-start-vagrant.html
- /en/getting-started.html
- /en/tutorials/index.html
---

<h3>Text search</h3>

<ul>
  <li><a href="text-search">Tutorial: Text Search</a>.
    A text search tutorial and introduction to text ranking with Vespa using traditional information retrieval techniques like BM25.
  </li>

  <li><a href="text-search-ml">Tutorial: Improving Text Search with Machine Learning</a>.
    This tutorial builds on the text search tutorial but introduces Learning to Rank to improve relevance.
  </li>
</ul>


<h3>Vector Search</h3>

<p>Learn how to use Vespa Vector Search in the <a href="../../querying/nearest-neighbor-search-guide">practical nearest neighbor search guide</a>.
It uses Vespa's support for <a href="../../querying/nearest-neighbor-search">nearest neighbor search</a>, there is
also support for fast <a href="../../querying/approximate-nn-hnsw">approximate nearest neighbor search</a> in Vespa.
The guide covers combining vector search with filters and how to perform hybrid search,
combining retrieval over inverted index structures with vector search.</p>


<h3>Hybrid Search</h3>

<p><a href="hybrid-search">Tutorial: Hybrid Text Search</a>.
A search tutorial and introduction to hybrid text ranking with Vespa,
combining BM25 with text embedding models.</p>


<h3>RAG (Retrieval-Augmented Generation)</h3>

<ul>
  <li><a href="rag-blueprint">Tutorial: The RAG Blueprint</a>.
    A tutorial that provides a blueprint for building high-quality RAG applications with Vespa. Includes evaluation and learning-to-rank (LTR).
  </li>
  <li><a href="../../llms-rag">Retrieval-augmented generation (RAG) in Vespa</a>.
  </li>
</ul>


<h3>Combining search and recommendation: The News tutorial</h3>

<p>Follow this series to learn how to build a complete application supporting both
content recommendation/personalization, navigation, and search.</p>

<ul>
  <li><a href="news-1-deploy-an-application">News 1: Getting Started</a>
  <li><a href="news-2-basic-feeding-and-query">News 2: Application Packages, Feeding, Query</a>
  <li><a href="news-3-searching">News 3: Sorting, Grouping and Ranking</a>
  <li><a href="news-4-embeddings">News 4: Embeddings</a>
  <li><a href="news-5-recommendation">News 5: Partial Updates, ANNs, Filtering</a>
  <li><a href="news-6-recommendation-with-searchers">News 6: Custom Searchers, Document Processors</a>
  <li><a href="news-7-recommendation-with-parent-child">News 7: Parent-Child, Tensor Ranking</a>
</ul>


<h3>ML Model Serving</h3>

<p>Learn how to use Vespa for ML model serving in <a href="../../stateless-model-evaluation.html">Stateless Model Evaluation</a>.
Vespa supports running inference with models from many popular ML frameworks, which can be used
for ranking, query classification, question answering, multi-modal retrieval, and more.</p>

<ul>
  <li><a href="../../onnx.html">Ranking with ONNX models</a>. Export models from
    popular deep learning frameworks such as <a href="https://pytorch.org/docs/stable/onnx.html">PyTorch</a>
    to <a href="https://onnx.ai/">ONNX</a> format for serving in Vespa. Vespa integrates with
    <a href="https://blog.vespa.ai/stateful-model-serving-how-we-accelerate-inference-using-onnx-runtime/">ONNX-Runtime</a>
    for <a href="https://blog.vespa.ai/stateless-model-evaluation/">accelerated inference</a>. Many ML frameworks
    support exporting models to ONNX, including <a href="http://onnx.ai/sklearn-onnx/">sklearn</a>.
  </li>
  <li><a href="../../lightgbm">Ranking with LightGBM models</a></li>
  <li><a href="../../xgboost">Ranking with XGBoost models</a></li>
  <li><a href="../../tensorflow">Ranking with TensorFlow models</a></li>
</ul>


<h3>Embedding Model Inference</h3>

<p>Vespa supports integrating <a href="../../embedding.html">embedding</a> models, which avoids transferring large amounts of embedding vector data
over the network and allows for efficient serving of embedding models.</p>
<ul>
  <li><a href="../../embedding.html#huggingface-embedder">Huggingface Embedder</a> Use single-vector embedding models from Hugging face</li>
  <li><a href="../../embedding.html#colbert-embedder">ColBERT Embedder</a> Use multi-vector embedding models </li>
  <li><a href="../../embedding.html#splade-embedder">Splade Embedder</a> Use sparse learned single vector embedding models</li>
</ul>


<h3>E-Commerce</h3>

<p>The <a href="../../use-case-shopping">e-commerce shopping sample application</a> demonstrates Vespa grouping,
true in-place partial updates, custom ranking, and more.</p>


<h3>More examples and sample applications</h3>

<p>There are many examples and starting applications on
<a href="https://github.com/vespa-engine/sample-apps/">GitHub</a>
and <a href="https://vespa-engine.github.io/pyvespa/index.html">Pyvespa examples</a>.</p>
