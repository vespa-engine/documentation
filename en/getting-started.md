---
# Copyright Vespa.ai. All rights reserved.
title: "Getting Started"
redirect_from:
- /en/vespa-quick-start-vagrant.html
---

Welcome to Vespa, the open big data serving engine!
Here you'll find resources for getting started.

|  |  |
| --- | --- |
| Quick Start | [**Quick start: Create and run a minimal Vespa application**](/en/cloud/getting-started)  Other ways to get started:   * [Quick start, application with Java components](/en/cloud/getting-started-java) * [Quick start, using the Pyvespa Python API](https://vespa-engine.github.io/pyvespa/) * Docker Desktop: [Install and run Vespa locally](vespa-quick-start.html) * Docker Desktop: [Install and run Vespa locally, with Java components](vespa-quick-start-java.html)   The [developer guide](/en/developer-guide.html) is an intro to developing, testing, and deploying applications.  Until you add multiple nodes an application can be deployed both on cloud and locally with no modifications. |
| Tutorials and Use Cases | Moving from the minimal quick start to more advanced use cases **Search**  * [Tutorial: Text Search](tutorials/text-search.html).   A text search tutorial and introduction to text ranking with Vespa using traditional information retrieval techniques like BM25. * [Tutorial: Hybrid Text Search](tutorials/hybrid-search.html).   A search tutorial and introduction to hybrid text ranking with Vespa, combining BM25 with text embedding models. * [Tutorial: Improving Text Search with Machine Learning](tutorials/text-search-ml.html).   This tutorial builds   on the [text search tutorial](tutorials/text-search.html) but introduces Learning to Rank to improve relevance.  **Vector Search** Learn how to use Vespa Vector Search in the [practical nearest neighbor search guide](nearest-neighbor-search-guide.html). It uses Vespa's support for [nearest neighbor search](nearest-neighbor-search.html), there is also support for fast [approximate nearest neighbor search](approximate-nn-hnsw.html) in Vespa. The guide covers combining vector search with filters and how to perform hybrid search, combining retrieval over inverted index structures with vector search. **RAG (Retrieval-Augmented Generation)**  * [Tutorial: RAG Blueprint](tutorials/rag-blueprint.html).   A tutorial that provides a blueprint for building high-quality RAG applications with Vespa. Includes evaluation and learning-to-rank (LTR). * [Retrieval-augmented generation (RAG) in Vespa](llms-rag.html).  **Recommendation** Learn how to use Vespa for content recommendation/personalization in the [News Search and Recommendation](tutorials/news-1-getting-started.html) tutorial set. **ML Model Serving** Learn how to use Vespa for ML model serving in [Stateless Model Evaluation](stateless-model-evaluation.html). Vespa supports running inference with models from many popular ML frameworks, which can be used for ranking, query classification, question answering, multi-modal retrieval, and more.   * [Ranking with ONNX models](onnx.html). Export models from   popular deep learning frameworks such as [PyTorch](https://pytorch.org/docs/stable/onnx.html)   to [ONNX](https://onnx.ai/) format for serving in Vespa. Vespa integrates with   [ONNX-Runtime](https://blog.vespa.ai/stateful-model-serving-how-we-accelerate-inference-using-onnx-runtime/)   for [accelerated inference](https://blog.vespa.ai/stateless-model-evaluation/). Many ML frameworks   support exporting models to ONNX, including [sklearn](http://onnx.ai/sklearn-onnx/). * [Ranking with LightGBM models](lightgbm.html) * [Ranking with XGBoost models](xgboost.html) * [Ranking with TensorFlow models](tensorflow.html)  **Embedding Model Inference** Vespa supports integrating [embedding](embedding.html) models, which avoids transferring large amounts of embedding vector data over the network and allows for efficient serving of embedding models.  * [Huggingface Embedder](embedding.html#huggingface-embedder) Use single-vector embedding models from Hugging face * [ColBERT Embedder](embedding.html#colbert-embedder) Use multi-vector embedding models * [Splade Embedder](embedding.html#splade-embedder) Use sparse learned single vector embedding models  **ML Model Lifecycle** The [Models hot swap tutorial](tutorials/models-hot-swap.html) shows a solution for changing the vector embedding model atomically while serving. It also extends the application to support multiple recommendation models while minimizing data duplication. Lastly, it demonstrates how to efficiently garbage collect obsolete content in an application. **E-Commerce Search** The [e-commerce shopping sample application](use-case-shopping.html) demonstrates Vespa grouping, true in-place partial updates, custom ranking, and more. **Examples and starting sample applications** There are many examples and starting applications on [GitHub](https://github.com/vespa-engine/sample-apps/) and [Pyvespa examples](https://vespa-engine.github.io/pyvespa/index.html). |
| Production deployment environments | Vespa can be deployed in multiple ways. These guides show how to deploy [multi-node applications](/en/operations-selfhosted/multinode-systems.html) in various environments.   * [Production deployments on Vespa Cloud](https://cloud.vespa.ai/en/production-deployment) * [Vespa high-availability multi-node template](https://github.com/vespa-engine/sample-apps/tree/master/examples/operations/multinode-HA) * [Vespa multinode testing and observability](https://github.com/vespa-engine/sample-apps/tree/master/examples/operations/multinode) * [Using Kubernetes with Vespa](/en/operations-selfhosted/using-kubernetes-with-vespa.html) * [AWS EC2 multinode](/en/operations-selfhosted/multinode-systems.html#aws-ec2) * [AWS ECS multinode](/en/operations-selfhosted/multinode-systems.html#aws-ecs)   See also [monitoring Vespa](/en/operations-selfhosted/monitoring.html). |
| Custom component development | Vespa applications can contain custom components that are run by Vespa, for example, when receiving queries or documents. The applications must be able to run on a JVM. While all the built-in behavior of Vespa can be invoked by a YQL query, advanced applications often choose to use plugin components to build queries from frontend requests as doing this closer to the data is faster and simpler.  See the quick starts with Java above to get started. The [Developer Guide](developer-guide.html) has more details. |

## Next Steps
* [Performance and scaling on Vespa](performance/).
* [Vespa query performance - practical guide](performance/practical-search-performance-guide.html).
* Overview of [Vespa APIs](api.html).
* [Frequently asked questions](faq.html).
* [Sample applications GitHub repo](https://github.com/vespa-engine/sample-apps).
* [Securing a Vespa installation](/en/operations-selfhosted/securing-your-vespa-installation.html).
* Follow the [Vespa Blog](https://blog.vespa.ai/) for product updates and use cases.
