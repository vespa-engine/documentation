---
# Copyright 2017 Yahoo Holdings. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root.
title: "Vespa Feed Sizing Guide"
---

<p>
Vespa is optimized to sustain a high feed load while serving -
also during planned and unplanned changes to the instance.
Vespa supports feed rates at memory speed,
this guide goes through how to configure, test and size the application
for optimal feed performance.
</p><p>
Read <a href="../writing-to-vespa.html">writing to Vespa</a> first.
This has an overview of Vespa, where the key takeaway is the <em>stateless container cluster</em>
and the <em>stateful content cluster</em>.
The processing of documents PUT to Vespa is run in the <em>container</em> cluster,
and includes both Vespa-internal processing like <a href="../linguistics.html#tokenization">tokenization</a>
and application custom code in <a href="../document-processing.html">document processing</a>.
The stateless cluster is primarily CPU bound,
read <a href="../indexing.html#multiple-container-clusters">indexing</a>
for how to separate search and write to different container clusters.
Other than that, make sure the container cluster has enough memory to avoid excessive GC -
the <a href="container-tuning.html">heap</a> must be big enough.
Allocate enough CPU for the indexing load.
</p><p>
All updates are written to the <a href="../proton.html#transaction-log">transaction log</a>.
This is sequential IO and rarely impacts write performance - and hence not covered in this guide.
</p><p>
The remainder of this document concerns how to configure the application
to optimize feed performance on the content node.
</p>



<h2 id="content-node">Content node</h2>
<p>
The content node runs the <a href="../proton.html">proton</a> process - overview:
</p>
<img src="../content/img/proton_feed.png" alt="Proton overview"/>
<p>
As there are multiple components and data structures involved,
this guide starts with the simplest examples and then adds optimizations and complexity.
Flushing of index structures is covered at the end of this guide.
</p>



<h2 id="streaming-search">Streaming search</h2>
<p>
The simplest for of indexing is <strong>no indexing</strong>.
In Vespa, this is called <em>streaming search</em> indexing mode.
Streaming search is optimized for write performance - the tradeoff is slow search.
Streaming search is hence great for applications like personal search, where data size <em>searched</em> is small -
read more in the <a href="../streaming-search.html">streaming search</a> guide.
</p><p>
Documents are written to the <a href="../document-summaries.html#document-store">document store</a> in all indexing modes -
this is where the copy of the PUT document is persisted.
See <em>Summary Manager + Document store</em> in illustration above.
In short, this is append operations to large files,
and (simplified) each PUT is one write.
</p><p>
PUT-ing documents to the document store can hence be thought of as appending to files using sequential IO,
expecting a high write rate, using little memory and CPU.
Writing a new version of a document (PUT a document that already exists) is the same as non-existent -
the index on the document is updated to point to the latest version isn both cases.
</p><p>
A partial UPDATE to a document incurs a read from the document store to get the current fields.
Then the new field values are applied and the new version or the document is written.
Hence, like a PUT with an extra read.
</p>



<h2 id="indices">Index</h2>
<p>
The majority of Vespa use cases operate on the full data set,
using <a href="../reference/services-content.html#document">indexed mode</a>:
<pre>
schema music {
    document music {
        field artist type string {
            indexing: summary | index
        }
</pre>
Observe that documents are written to summary (i.e. document store) as in streaming mode,
but there is also an <em>index</em>.
See <em>Index Manager + Index</em> in illustration above.
</p><p>
Refer to proton <a href="../proton.html#index">index</a> for the index write.
In short, it updates the memory index, which is flushed regularly.
The PUT to the index is hence a memory only operation, but uses CPU to update the index.
</p><p>
A partial UPDATE is as in streaming search, plus the memory index update.
</p>



<h2 id="attribute">Attribute</h2>
<p>
Some applications have a limited set of documents,
with a high change rate to fields in the documents
(e.g. stock prices - number of stocks is almost fixed, prices changes constantly).
Such applications are easily write bound.
</p><p>
To real-time update fields in high volume, use <a href="../attributes.html">attribute</a> fields:
<pre>
schema ticker {
    document ticker {
        field price type float {
            indexing: summary | attribute
        }
</pre>
Attribute fields are not stored in the document store, there is hence no IO (except sequential flushing).
This enables application to write at memory speed to vespa - a 10k update rate per node is possible.
</p>



<h3 id="redundancy-settings">Redundancy settings</h3>
<p>
To achieve memory-only updates,
make sure all attributes to update are <a href="../proton.html#sub-databases">ready</a>,
meaning the content node has loaded the attribute into memory:
<ul>
  <li>
    One way to ensure this is to set
    <a href="../reference/services-content.html#searchable-copies">searchable copies</a> equal to
    <a href="../reference/services-content.html#redundancy">redundancy</a> -
    i.e. all nodes that has a replica of the document has loaded it as searchable
  </li><li>
    Another way is by setting
    <a href="../reference/schema-reference.html#attribute">fast-access</a> on each attribute to update
  </li>
</ul>
</p>



<h3 id="debugging-performance">Debugging performance</h3>
<p>
When debugging update performance, it is useful to know if an update hits the
<a href="../document-summaries.html#document-store">document store</a> or not.
Enable <em>spam</em> log level and look for <em>SummaryAdapter::put</em> - then do an update:
<pre>
$ <a href="../reference/vespa-cmdline-tools.html#vespa-logctl">vespa-logctl</a> searchnode:proton.server.summaryadapter spam=on
.proton.server.summaryadapter    ON  ON  ON  ON  ON  ON OFF  ON

$ <a href="../reference/vespa-cmdline-tools.html#vespa-logfmt">vespa-logfmt</a> -l all -f | grep 'SummaryAdapter::put'
[2019-10-10 12:16:47.339] SPAM    : searchnode       proton.proton.server.summaryadapter	summaryadapter.cpp:45 SummaryAdapter::put(serialnum = '12', lid = 1, stream size = '199')
</pre>
Existence of such log messages indicates that the update was accessing the document store.
</p>
<!-- ToDo: when we have log for get and remove as well, add to documentation
https://github.com/vespa-engine/vespa/blob/master/searchcore/src/vespa/searchcore/proton/server/summaryadapter.cpp#L75
-->



<h2 id="multivalue-attribute">Multivalue attribute</h2>
<p>
<a href="../reference/schema-reference.html#field">Multivalued attributes</a> are
<em>weightedset</em>, <em>array of struct/map</em>, <em>map of struct/map</em> and <em>tensor</em>.
The attributes have different characteristics, which affects write performance.
Generally, updates to multivalue fields are more expensive as the field size grows.
<table class="table">
<tr>
  <th>weightedset</th>
  <td>
    Memory-only operation when updating: read full set, update, write back.
    Make the update as inexpensive as possible using numeric types instead of strings, where possible
    Example: a weighted set of string with many (1000+) elements.
    Adding an element to the set means an enum store lookup/add and add/sort of the attribute multivalue map -
    details in <a href="../attributes.html">attributes</a>.
    Use a numeric type instead to speed this up - this has no string comparisons.
  </td>
</tr><tr>
  <th style="white-space: nowrap">array/map of struct/map</th>
  <td>
    Update to array of struct/map and map of struct/map requires a read from the
    <a href="../document-summaries.html#document-store">document store</a> and will hence reduce update rate -
    see <a href="https://github.com/vespa-engine/vespa/issues/10892">#10892</a>.
  </td>
</tr><tr>
  <th>tensor</th>
  <td>
    Updating tensor cell values is a memory-only operation: copy tensor, update, write back.
    For large tensors, this implicates reading and writing a large chunk of memory for single cell updates.
  </td>
</tr>
</table>
</p>



<h2 id="parent-child">Parent/child</h2>
<p>
<a href="../parent-child.html">Parent documents</a> are global, i.e. has a replica on all nodes.
Writing to fields in parent documents often simplify logic,
compared to the de-normalized case where <span style="text-decoration: underline">all</span>
(child) documents are updated.
Write performance depends on the average number of child documents vs number of nodes in the cluster - examples:
<ul>
  <li>10-node cluster, avg number of children=100, redundancy=2:
    A parent write means 10 writes, compared to 200 writes, or 20x better</li>
  <li>50-node cluster, avg number of children=10, redundancy=2:
    A parent write means 50 writes, compared to 20 writes, or 2.5x worse</li>
</ul>
Hence, the more children, the better performance effect for parent writes.
</p>



<h2 id="batch-using-visibility-delay">Batch using visibility-delay</h2>
<p>
Updating memory structures takes CPU and can limit feed performance.
This applies to indexed and attribute fields -
like the memory index, attributes
and data structures om top of attributes like <a href="../attributes.html#fast-search">fast-search</a>.
Use <a href="../reference/services-content.html#visibility-delay">visibility-delay</a>
to batch writes on the content nodes and save CPU.
</p><p>
Example test results - throughput improvements, using <em>visibility-delay</em>=1.0 seconds:
<ul>
  <li>+20% during initial feeding</li>
  <li>+15% during re-feeding</li>
  <li>+120% during removing of 1M documents</li>
</ul>
The results depend on number of index and attribute fields in the schema,
and the content of the documents.
</p>



<h2 id="conditional-updates">Conditional updates</h2>
<p>
A conditional update looks like:
<pre>
{
    "update" : "id:namespace:myDoc::1",
    "condition" : "myDoc.myField == \"abc\"",
    "fields" : { "myTimestamp" : { "assign" : 1570187817 } }
}
</pre>
If the <a href="../document-summaries.html#document-store">document store</a>
is accessed when evaluating the condition, performance drops.
Conditions should be evaluated using attribute values for high performance -
in the example above, <em>myField</em> should be an attribute.
</p><p>
Note: If the condition uses struct or map, values are read from the document store:
<pre>
    "condition" : "myDoc.myMap{1} == 3"
</pre>
This is true even though all struct fields are defined as attribute.
Improvements to this is tracked in
<a href="https://github.com/vespa-engine/vespa/issues/10892">#10892</a>.
</p>
<!-- ToDo: can probably use the "SummaryAdapter::get" log message above, once made -->



<h2 id="client-roundtrips">Client roundtrips</h2>
<p>
Consider the difference when sending two fields assignments to the same document:
<pre>
{
    "update" : "id:namespace:doctype::1",
    "fields" : {
        "myMap{1}" : { "assign" : { "timestamp" : 1570187817 } }
        "myMap{2}" : { "assign" : { "timestamp" : 1570187818 } }
    }
}
</pre>

<pre>
{
    "update" : "id:namespace:doctype::1",
    "fields" : {
        "myMap{1}" : { "assign" : { "timestamp" : 1570187817 } }
    }
}
{
    "update" : "id:namespace:doctype::1",
    "fields" : {
        "myMap{2}" : { "assign" : { "timestamp" : 1570187818 } }
    }
}
</pre>
In the first case, <em>one</em> update operation is sent from the <a href="../vespa-http-client.html">vespa-http-client</a> -
in the latter, the client will send the second update operation <em>after</em> receiving and ack for the first.
When updating multiple fields, put the updates in as few operations as possible.
See <a href="../content/content-nodes.html#ordering">Ordering details</a>.
</p>



<h2 id="feed-vs-search">Feed vs search</h2>
<p>
A content node normally has a fixed set of resources (CPU, memory, disk).
Configure the CPU allocation for feeding vs. searching in
<a href="../reference/services-content.html#feeding">concurrency</a> -
value from 0 to 1.0 - a higher value means more CPU resources for feeding.
</p>



<h2 id="feed-testing">Feed testing</h2>
<p>
When testing for feeding capacity:
<ol>
  <li>Use the <a href="../vespa-http-client.html">vespa-http-client</a> in asynchronous mode.</li>
  <li>Test using one content node to find its capacity</li>
  <li>Test feeding performance by adding feeder instances.
    Make sure network and CPU (content and container node) usage increases, until saturation.</li>
  <li>See troubleshooting at end to make sure there are no errors</li>
</ol>
Other scenarios: Feed testing for capacity for sustained load in a system in steady state,
during state changes, during query load.
</p>



<h2 id="troubleshooting">Troubleshooting</h2>
<table class="table">
<tr id="metrics">
  <th>Metrics</th>
  <td>
    <p>
    Use <a href="../reference/metrics.html#process-metrics-api">metrics</a> from content nodes and look at queues -
    queue wait time and queue size (all metrics in milliseconds):
<pre>
vds.filestor.alldisks.averagequeuewait.sum
vds.filestor.alldisks.queuesize
</pre>
    Check content node metrics across all nodes to see if there are any outliers. Also check
<pre>
vds.filestor.alldisks.allthreads.update.sum.latency
</pre>
    </p>
  </td>
</tr><tr id="failure-rates">
  <th>Failure rates</th>
  <td>
    <p>
    Inspect these metrics for failures during load testing:
<pre>
vds.distributor.updates.sum.latency
vds.distributor.updates.sum.ok
vds.distributor.updates.sum.failures.total
vds.distributor.puts.sum.latency
vds.distributor.puts.sum.ok
vds.distributor.puts.sum.failures.total
vds.distributor.removes.sum.latency
vds.distributor.removes.sum.ok
vds.distributor.removes.sum.failures.total
</pre>
    </p>
  </td>
</tr><tr id="blocked-feeding">
  <th>Blocked feeding</th>
  <td>
<p>
This metric should be 0 - refer to <a href="../writing-to-vespa.html#feed-block">feed block</a>:
<pre>
content.proton.resource_usage.feeding_blocked
</pre>
</p>
  </td>
</tr><tr id="concurrent-mutations">
  <th style="white-space: nowrap">Concurrent mutations</th>
  <td>
    <p>
    Multiple clients updating the same document concurrently will stall writes:
<pre>
vds.distributor.updates.sum.failures.concurrent_mutations
</pre>
    Mutating client operations towards a given document ID are sequenced on the
    <a href="../content/content-nodes.html#distributor">distributors</a>.
    If an operation is already active towards a document,
    a subsequently arriving one will be bounced back to the client with a transient failure code.
    Usually this happens when users send feed from multiple clients concurrently without synchronisation.
    Note that feed operations sent by a single client are sequenced client-side,
    so this should not be observed with a single client only.
    Bounced operations are never sent on to the backends and should not cause elevated latencies there,
    although the client will observe higher latencies due to automatic retries with back-off.
    </p>
  </td>
</tr><tr id="wrong-distribution">
  <th>Wrong distribution</th>
  <td>
    <p>
<pre>
vds.distributor.updates.sum.failures.wrongdistributor
</pre>
    Indicates that clients keep sending to the wrong distributor.
    Normally this happens infrequently
    (but is <em>does</em> happen on client startup or distributor state transitions),
    as clients update and cache all state required to route directly to the correct distributor
    (Vespa uses a deterministic CRUSH-based algorithmic distribution).
    Some potential reasons for this:
    <ol>
      <li>Clients are being constantly re-created with no cached state.</li>
      <li>The system is in some kind of flux where the underlying state keeps changing constantly.</li>
      <li>The client distribution policy has received so many errors
        that it throws away its cached state to start with a clean slate to
        e.g. avoid the case where it only has cached information for the bad side of a network partition.</li>
      <li>The system has somehow failed to converge to a shared cluster state,
        causing parts of the cluster to have a different idea of the correct state than others.</li>
    </ol>
    </p>
  </td>
</tr><tr id="cluster-out-of-sync">
  <th>Cluster out of sync</th>
  <td>
    <p>
    <em>update_puts/gets</em> indicate "two-phase" updates: <!-- ToDo: explain two-phase updates / link -->
<pre>
vds.distributor.update_puts.sum.latency
vds.distributor.update_puts.sum.ok
vds.distributor.update_gets.sum.latency
vds.distributor.update_gets.sum.ok
vds.distributor.update_gets.sum.failures.total
vds.distributor.update_gets.sum.failures.notfound
</pre>
    If replicas are out of sync,
    updates cannot be applied directly on the replica nodes
    as they risk ending up with diverging state.
    In this case, Vespa performs an explicit read-consolidate-write (write repair) operation on the distributors.
    This is usually a lot slower than the regular update path because it doesnâ€™t happen in parallel.
    It also happens in the write path of other operations,
    so risks blocking these if the updates are expensive in terms of CPU.
    </p><p>
    Replicas being out of sync is by definition not the expected steady state of the system.
    For example, replica divergence can happen if one or more replica nodes are unable to process or persist operations.
    Track (pending) merges:
<pre>
vds.idealstate.buckets
vds.idealstate.merge_bucket.pending
vds.idealstate.merge_bucket.done_ok
vds.idealstate.merge_bucket.done_failed
</pre>
    </p>
  </td>
</tr>
</table>
