---
# Copyright 2017 Yahoo Holdings. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root.
title: "Tensor Evaluation Reference"
---

<p>
A tensor is a set of named <em>dimensions</em> defining its <em>order</em>
and a set of values located in the space of those dimensions:

<ul class="semicompact">
  <li><em>Cell</em>: A value located in the dimension space.
    Consists of a cell address and the floating point value at that address.</li>
  <li><em>Address</em>: A set of key-values where each key is a <em>dimension</em> from the set of dimensions of the tensor,
    and each value is a <em>label</em> (integer or identifier) determining the cells location in that dimension.</li>
</ul>

The set of dimensions, cell values and cell address key-values can be of any size including zero.
A dimension can be either mapped or indexed. Mapped dimensions use string identifiers as labels in the cell addresses (like a map),
while indexed dimensions use integers in the range <code>[0,N&gt;</code> (like an array), where N is the size of the dimension.
The dimensions of a tensor defines its type, see the <a href="tensor.html#tensor-type-spec">tensor type spec</a>.
</p>


<h2 id="tensor-type-spec">Tensor type spec</h2>

<p>
    Contained in <code><a href="#constant">constant</a></code> or <code><a href="#type:tensor">tensor field type</a></code>.
    Specifies the tensor type for a tensor.
    A tensor type contains a list of dimensions on the format:
<pre>
tensor(dimension-1,dimension-2,...,dimension-N)
</pre>
A dimension is specified as follows:
<ul>
    <li><code>dimension-name{}</code> - a mapped dimension.
    <li><code>dimension-name[size]</code> - an indexed dimension.
</ul>
The tensor type for a tensor with two mapped dimensions <em>x</em> and <em>y</em> looks like:
<pre>
tensor(x{},y{})
</pre>
Example tensor with this type:
<pre>{% raw %}
{{x:a,y:b}:10, {x:c,y:d}:20}
{% endraw %}</pre>
The tensor type for a tensor with two indexed dimensions <em>x</em> and <em>y</em> with sizes 3 and 2 respectively looks like this:
<pre>
tensor(x[3],y[2])
</pre>
Example tensor with this type (representing a matrix):
<pre>{% raw %}
{{x:0,y:0}:1, {x:0,y:1}:2,
 {x:1,y:0}:3, {x:1,y:1}:5,
 {x:2,y:0}:7, {x:2,y:1}:11}
{% endraw %}</pre>
Note that the labels are indexes in the range <em>[0,dimension-size&gt;</em>
</p><p>
    A tensor with both mapped and indexed dimensions is mixed:
<pre>
tensor(x[2],y{})
</pre>
Example:
<pre>{% raw %}
{{x:0,y:a}:10, {x:0,y:b}:20,
 {x:1,y:a}:5,  {x:1,y:b}:7}
{% endraw %}</pre>
</p>


<h2 id="tensor-literal-form">Tensor literal form</h2>

The standard literal form of tensors specified verbatim in ranking expressions is as follows (expressed in EBNF):
<pre>
literal tensor = ( tensor-type-spec ":" )? "{" cells "}" ;
cells = | cell , { "," cell } ;
cell = "{" address "}:" scalar ;
address = | element, { "," element } ;
element = dimension ":" label ;
dimension = integer | string ;
label = integer | string ;
</pre>

<p>If no type spec is included the type is inferred from cells.</p>

<p>Tensors which are completely dense can also use the dense literal form, where
just the numbers are given, wrapped in square brackets in right dimension adjacent order.
This form reequires a dimension to be specified.</p>


<h3 id="literal-form-examples">Literal form examples</h3>

<p>
An empty tensor:
<pre>
{}
</pre>
A single value tensor with a single mapped dimension <em>x</em>:
<pre>
{ {x:foo}:5.0 }
</pre>
A tensor with multiple values and mapped dimensions <em>x</em> and <em>y</em>:
<pre>
{ {x:foo, y:bar}:5.0, {x:foo, y:baz}:7.0 }
</pre>
A tensor where type is specified explicitly with a single indexed dimension <em>x</em> representing a vector:
<pre>
tensor(x[3]):{ {x:0}:3.0, {x:1}:5.0, {x:2}:7.0 }
</pre>
The same tensor in dense form:
<pre>
tensor(x[3]):[3.0, 5.0, 7.0]
</pre>
A matrix in dense form. Note that the values for the right-most dimension (y) are adjacent, so e.g
the value 3 is here assigned to the cell {x:0,y:2}:
<pre>
tensor(x[2],y[3]):[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]
</pre>
Also note that left and right dimension here is by alphabetical order of the dimension names, the order in which
they are given in the type specification is irrelevant. The inner brackets are syntactic sugar and can
be omitted, so the above is equivalent to
<pre>
tensor(x[2],y[3]):[1.0, 2.0, 3.0, 4.0, 5.0, 6.0]
</pre>

</p>


<h2 id="operations">Operations</h2>

<p>
The following set of tensors operations are available to use in ranking
expressions. We group the operations in primitive functions and convenience
functions that can be implemented by primitive functions.
</p>

<h3 id="primitive-functions">Primitive functions</h3>

<table class="table">
  <thead></thead>
<tbody>
<tr>
    <td><a href="#map">map</a></td>
    <td style="white-space:nowrap;">map(tensor, f(x)(expr))</td>
    <td>Returns a new tensor with the lambda function defined in <code>f(x)(expr)</code> applied to each cell.</td>
</tr>
<tr>
    <td><a href="#reduce">reduce</a></td>
    <td style="white-space:nowrap;">reduce(tensor, aggregator, dim1, dim2, ...)</td>
    <td>Returns a new tensor with the <code>aggregator</code> applied across dimensions dim1, dim2, etc. If no dimensions are specified, reduce over all dimensions.</td>
</tr>
<tr>
    <td><a href="#join">join</a></td>
    <td style="white-space:nowrap;">join(tensor1, tensor2, f(x,y)(expr))</td>
    <td>Returns a new tensor constructed from the <em>natural join</em> between <code>tensor1</code> and <code>tensor2</code>, with the resulting cells having the value as calculated from <code>f(x,y)(expr)</code>, where <code>x</code> is the cell value from <code>tensor1</code> and <code>y</code> from <code>tensor2</code>.</td>
</tr>
<tr>
    <td><a href="#tensor">tensor</a></td>
    <td style="white-space:nowrap;">tensor(tensor-type-spec)(expr)</td>
    <td>Generates new tensors according to type specification and expression <code>expr</code>.</td>
</tr>
<tr>
    <td><a href="#rename">rename</a></td>
    <td style="white-space:nowrap;">rename(tensor, dimensions-to-rename, new-names)</td>
    <td>Renames one or more dimensions in the tensor.</td>
</tr>
<tr>
    <td><a href="#concat">concat</a></td>
    <td style="white-space:nowrap;">concat(tensor1, tensor2, dim)</td>
    <td>Concatenates two tensors along dimension <code>dim</code>.</td>
</tr>
</tbody>
</table>


<h4 id="lambda">Lambda functions in primitive functions</h4>

<p>
Some of the primitive functions accept lambda functions that are evaluated
and applied to a set of tensor cells. The functions contain a single expression
that have the same format and built-in functions as
<a href="ranking-expressions.html">general ranking expressions</a>.
However, the atoms are the arguments defined in the argument list of the lambda.
</p>

<p>
The expression cannot access variables or data structures outside of the lambda,
i.e. they are not closures.
</p>

<p>
Examples:
</p>

<pre>
f(x)(abs(x))
f(x,y)(if(x &lt; y, 0, 1))
</pre>


<h4 id="map">- Map</h4>

<p>
Arguments:
<ul>
    <li><code>tensor</code>: a tensor.</li>
    <li><code>f(x)(expr)</code>: a <a href="#lambda">lambda function</a> with one argument.</li>
</ul>
</p>

<p>
Returns a new tensor where the expression in the lambda function is
evaluated in each cell in <code>tensor</code>.
</p>

<p>
Examples:
</p>

<pre>
map(t, f(x)(abs(x)))
map(t, f(i)(if(i &lt; 0, 0, i)))
</pre>

<h4 id="reduce">- Reduce</h4>

<p>
Arguments:
<ul>
    <li><code>tensor</code>: a tensor.</li>
    <li><code>aggregator</code>: the aggregator to use. See below.</li>
    <li><code>dim1, dim2, ...</code>: the dimensions to reduce over. Optional.</li>
</ul>
</p>

<p>
Returns a new tensor with the aggregator applied across dimensions
<code>dim1</code>, <code>dim2</code>, etc.
If no dimensions are specified, reduce over all dimensions.
</p>

<p>
Available aggregators are:
<ul>
    <li><code>avg</code>: arithmetic mean</li>
    <li><code>count</code>: number of elements</li>
    <li><code>prod</code>: product of all values</li>
    <li><code>sum</code>: sum of all values</li>
    <li><code>max</code>: maximum value</li>
    <li><code>min</code>: minimum value</li>
</ul>
</p>

<p>
Examples:
</p>

<pre>
reduce(t, sum)         # Sum all values in tensor
reduce(t, count, x)    # Count number of cells along dimension x
</pre>

<h4 id="join">- Join</h4>

<p>
Arguments:
<ul>
    <li><code>tensor1</code>: a tensor.</li>
    <li><code>tensor2</code>: a tensor.</li>
    <li><code>f(x,y)(expr)</code>: a <a href="#lambda">lambda function</a> with two arguments.</li>
</ul>
</p>

<p>
Returns a new tensor constructed from the <em>natural join</em>
between <code>tensor1</code> and <code>tensor2</code>, with the
resulting cells having the value as calculated from <code>f(x,y)(expr)</code>,
where <code>x</code> is the cell value from <code>tensor1</code> and
<code>y</code> from <code>tensor2</code>.
</p>

<p>
Formally, the result of the <code>join</code> is a new tensor with dimensions
the union of dimension between <code>tensor1</code> and <code>tensor2</code>.
The cells are the set of all combinations of cells that have equal values
on their common dimensions.
</p>

<p>
Examples:
</p>

{% raw %}
<pre>
t1 = {{x:0}: 1.0, {x:1}: 2.0}
t2 = {{x:0,y:0}: 3.0, {x:0,y:1}: 4.0, {x:1,y:0}: 5.0, {x:1,y:1}: 6.0}

join(t1, t2, f(x,y)(x * y)) = {{x:0,y:0}: 3.0, {x:0,y:1}: 4.0, {x:1,y:0}: 10.0, {x:1,y:1}: 12.0}

reduce(join(t1, t2, f(x,y)(x * y)), sum) = 29.0
</pre>
{% endraw %}


<h4 id="tensor">- tensor</h4>

<p>
Arguments:
<ul>
    <li><code>tensor-type-spec</code>: a <a href="#tensor-type-spec">indexed tensor type specification.</a></li>
    <li><code>(expr)</code>: a <a href="#lambda">lambda function</a> expressing how to generate the tensor.</li>
</ul>
</p>

<p>
Generates new tensors according to the type specification and expression <code>expr</code>. The tensor
type must be an indexed tensor (e.g. <code>tensor(x[10])</code>). The expression in <code>expr</code>
will be evaluated for each cell.
The arguments in the expression is implicitly the names of the dimensions defined in the type spec.
</p>

<p>
Useful for creating transformation tensors.
</p>

<p>
Examples:
</p>

{% raw %}
<pre>
tensor(x[3])(x) = {{x:0}: 0.0, {x:1}: 1.0, {x:2}: 2.0}
tensor(x[2],y[2])(x == y) = {{x:0,y:0}: 1.0, {x:0,y:1}: 0.0, {x:1,y:0}: 0.0, {x:1,y:1}: 1.0}
</pre>
{% endraw %}


<h4 id="rename">- rename</h4>

<p>
Arguments:
<ul>
    <li><code>tensor</code>: a tensor.</li>
    <li><code>dim-to-rename</code>: a dimension, or list of dimensions, to rename.</li>
    <li><code>new-names</code>: new names for the dimensions listed above.</li>
</ul>
</p>

<p>
Returns a new tensor with one or more dimension renamed.
</p>

<p>
Examples:
</p>

{% raw %}
<pre>
t1 = {{x:0,y:0}: 1.0, {x:0,y:1}: 0.0, {x:1,y:0}: 0.0, {x:1,y:1}: 1.0}

rename(t1,x,z) = {{z:0,y:0}: 1.0, {z:0,y:1}: 0.0, {z:1,y:0}: 0.0, {z:1,y:1}: 1.0}
rename(t1,(x,y),(i,j)) = {{i:0,j:0}: 1.0, {i:0,j:1}: 0.0, {i:1,j:0}: 0.0, {i:1,j:1}: 1.0}
</pre>
{% endraw %}


<h4 id="concat">- concat</h4>

<p>
Arguments:
<ul>
    <li><code>tensor1</code>: a tensor or scalar.</li>
    <li><code>tensor2</code>: a tensor or scalar.</li>
    <li><code>dim</code>: the dimension to concatenate along.</li>
</ul>
</p>

<p>
Returns a new tensor with the two tensors <code>tensor1</code> and
<code>tensor2</code> concatenated along dimension <code>dim</code>. The tensors
can also be scalars.
</p>

<p>
Examples:
</p>

{% raw %}
<pre>
t1 = {{x:0}: 0.0, {x:1}: 1.0}
t2 = {{x:0}: 2.0, {x:1}: 3.0}

concat(t1,t2,x) = {{x:0}: 0.0, {x:1}: 1.0}, {x:2}: 2.0, {x:3}: 3.0}}
</pre>
{% endraw %}


<h3>Non-primitive functions</h3>

<p>
Non-primitive functions can be implemented by primitive functions,
but are not necessarily so for performance reasons.
</p>

<table class="table">
  <thead></thead>
<tbody>
<tr>
    <td>abs(t)</td>
    <td>
        <code>map(t, f(x)(abs(x)))</code> <br />
        Absolute value of all elements.
    </td>
</tr>
<tr>
    <td>acos(t)</td>
    <td>
        <code>map(t, f(x)(acos(x)))</code> <br />
        Arc cosine of all elements.
    </td>
</tr>
<tr>
    <td>t1 + t2 (add)</td>
    <td>
        <code>join(t1, t2, f(x,y)(x + y))</code> <br />
        Join and sum tensors <code>t1</code> and <code>t2</code>.
    </td>
</tr>
<tr>
    <td>argmax(t)</td>
    <td>
        <code>join(t, max(t), f(x,y)(if (x == y, 1, 0)))</code> <br />
        Returns a tensor with cell(s) of the highest value(s) in the tensor set to 1.
    </td>
</tr>
<tr>
    <td>argmin(t)</td>
    <td>
        <code>join(t, min(t), f(x,y)(if (x &gt;= y, 0, 1)))</code> <br />
        Returns a tensor with cell(s) of the lowest value(s) in the tensor set to 1.
    </td>
</tr>
<tr>
    <td>asin(t)</td>
    <td>
        <code>map(t, f(x)(asin(x)))</code> <br />
        Arc sine of all elements.
    </td>
</tr>
<tr>
    <td>atan(t)</td>
    <td>
        <code>map(t, f(x)(atan(x)))</code> <br />
        Arc tangent of all elements.
    </td>
</tr>
<tr>
    <td>atan2(t1,t2)</td>
    <td>
        <code>join(t1, t2, f(x,y)(atan2(x,y)))</code> <br />
        Arctangent of <code>t1</code> and <code>t2</code>/
    </td>
</tr>
<tr>
    <td>avg(t, dim)</td>
    <td>
        <code>reduce(t, avg, dim)</code> <br />
        Reduce the tensor with the <code>average</code> aggregator along dimension <code>dim</code>.
    </td>
</tr>
<tr>
    <td>ceil(t)</td>
    <td>
        <code>map(t, f(x)(ceil(x)))</code> <br />
        Ceiling of all elements.
    </td>
</tr>
<tr>
    <td>count(t, dim)</td>
    <td>
        <code>reduce(t, count, dim)</code> <br />
        Reduce the tensor with the <code>count</code> aggregator along dimension <code>dim</code>.
    </td>
</tr>
<tr>
    <td>cos(t)</td>
    <td>
        <code>map(t, f(x)(cos(x)))</code> <br />
        Cosine of all elements.
    </td>
</tr>
<tr>
    <td>cosh(t)</td>
    <td>
        <code>map(t, f(x)(cosh(x)))</code> <br />
        Hyperbolic cosine of all elements.
    </td>
</tr>
<tr>
    <td>diag(n1,n2)</td>
    <td>
        <code>tensor(i[n1],j[n2])(if (i==j, 1.0, 0.0)))</code> <br />
        Returns a tensor with the diagonal set to 1.0.
    </td>
</tr>
<tr>
    <td>t1 / t2 (div)</td>
    <td>
        <code>join(t1, t2, f(x,y)(x / y))</code> <br />
        Join and divide tensors <code>t1</code> and <code>t2</code>.
    </td>
</tr>
<tr>
    <td>elu(t)</td>
    <td>
        <code>map(t, f(x)(if(x &lt; 0, exp(x)-1, x)))</code> <br />
        <a href="https://arxiv.org/abs/1511.07289">Exponential linear unit</a>.
    </td>
</tr>
<tr>
    <td>t1 == t2 (equal)</td>
    <td>
        <code>join(t1, t2, f(x,y)(x == y))</code> <br />
        Join and determine if each element in <code>t1</code> and <code>t2</code> are equal.
    </td>
</tr>
<tr>
    <td>exp(t)</td>
    <td>
        <code>map(t, f(x)(exp(x)))</code> <br />
        Exponential function (e^x) of each element.
    </td>
</tr>
<tr>
    <td>floor(t)</td>
    <td>
        <code>map(t, f(x)(floor(x)))</code> <br />
        Floor of each element.
    </td>
</tr>
<tr>
    <td>t1 &gt; t2 (greater)</td>
    <td>
        <code>join(t1, t2, f(x,y)(x &gt; y))</code> <br />
        Join and determine if each element in <code>t1</code> is greater than <code>t2</code>.
    </td>
</tr>
<tr>
    <td>t1 &gt;= t2 (greater or equals)</td>
    <td>
        <code>join(t1, t2, f(x,y)(x &gt;= y))</code> <br />
        Join and determine if each element in <code>t1</code> is greater than or equals <code>t2</code>.
    </td>
</tr>
<tr>
    <td>t1 &lt; t2 (less)</td>
    <td>
        <code>join(t1, t2, f(x,y)(x &lt; y))</code> <br />
        Join and determine if each element in <code>t1</code> is less than <code>t2</code>.
    </td>
</tr>
<tr>
    <td>t1 &lt;= t2 (less equals)</td>
    <td>
        <code>join(t1, t2, f(x,y)(x &lt;= y))</code> <br />
        Join and determine if each element in <code>t1</code> is less than or equals <code>t2</code>.
    </td>
</tr>
<tr>
    <td>l1_normalize(t, dim)</td>
    <td>
        <code>join(t, reduce(t, sum, dim), f(x,y) (x / y))</code> <br />
        L1 normalization: <code>t / sum(t, dim)</code>.
    </td>
</tr>
<tr>
    <td>l2_normalize(t, dim)</td>
    <td>
        <code>join(t, map(reduce(map(t, f(x)(x * x)), sum, dim), f(x)(sqrt(x))), f(x,y)(x / y))</code> <br />
        L2 normalization: <code>t / sqrt(sum(t^2, dim)</code>.
    </td>
</tr>
<tr>
    <td>log(t)</td>
    <td>
        <code>map(t, f(x)(log(x)))</code> <br />
        Natural logarithm of each element.
    </td>
</tr>
<tr>
    <td>log10(t)</td>
    <td>
        <code>map(t, f(x)(log10(x)))</code> <br />
        Logarithm with base 10 of each element.
    </td>
</tr>
<tr>
    <td>matmul(t1, t2, dim)</td>
    <td>
        <code>reduce(join(t1, t2, f(x,y)(x * y)), sum, dim)</code> <br />
        Matrix multiplication of two tensors. This is the product of the two tensors summed along a shared dimension.
    </td>
</tr>
<tr>
    <td>max(t, dim)</td>
    <td>
        <code>reduce(t, max, dim)</code> <br />
        Reduce the tensor with the <code>max</code> aggregator along dimension <code>dim</code>.
    </td>
</tr>
<tr>
    <td>max(t1,t2)</td>
    <td>
        <code>join(t1, t2, f(x,y)(max(x,y)))</code> <br />
        Join and return the max of <code>t1</code> or <code>t2</code>. Arguments can be scalars.
    </td>
</tr>
<tr>
    <td>min(t, dim)</td>
    <td>
        <code>reduce(t, min, dim)</code> <br />
        Reduce the tensor with the <code>min</code> aggregator along dimension <code>dim</code>.
    </td>
</tr>
<tr>
    <td>min(t1,t2)</td>
    <td>
        <code>join(t1, t2, f(x,y)(min(x,y)))</code> <br />
        Join and return the minimum of <code>t1</code> or <code>t2</code>. Arguments can be scalars.
    </td>
</tr>
<tr>
    <td>mod(t,constant)</td>
    <td>
        <code>map(t, f(x)(mod(x,constant)))</code> <br />
        Modulus of <code>constant</code> with each element.
    </td>
</tr>
<tr>
    <td>t1 * t2 (mul)</td>
    <td>
        <code>join(t1, t2, f(x,y)(x * y))</code> <br />
        Join and multiply tensors <code>t1</code> and <code>t2</code>.
    </td>
</tr>
<tr>
    <td>t1 != t2 (not equal)</td>
    <td>
        <code>join(t1, t2, f(x,y)(x != y))</code> <br />
        Join and determine if each element in <code>t1</code> and <code>t2</code> are not equal.
    </td>
</tr>
<tr>
    <td>pow(t,constant)</td>
    <td>
        <code>map(t, f(x)(pow(x,constant)))</code> <br />
        Raise each element to the power of <code>constant</code>.
    </td>
</tr>
<tr>
    <td>prod(t, dim)</td>
    <td>
        <code>reduce(t, prod, dim)</code> <br />
        Reduce the tensor with the <code>product</code> aggregator along dimension <code>dim</code>.
    </td>
</tr>
<tr>
    <td>random(n1, n2, ...)</td>
    <td>
        <code>tensor(i1[n1],i2[n2],...)(random(1.0))</code> <br />
        Returns a tensor with random values between 0.0 and 1.0, uniform distribution.
    </td>
</tr>
<tr>
    <td>range(n)</td>
    <td>
        <code>tensor(i[n])(i)</code> <br />
        Returns a tensor with increasing values.
    </td>
</tr>
<tr>
    <td>relu(t)</td>
    <td>
        <code>map(t, f(x)(max(0,x)))</code> <br />
        Rectified linear unit.
    </td>
</tr>
<tr>
    <td>round(t)</td>
    <td>
        <code>map(t, f(x)(round(x)))</code> <br />
        Round each element.
    </td>
</tr>
<tr>
    <td>sigmoid(t)</td>
    <td>
        <code>map(t, f(x)(1.0 / (1.0 + exp(0.0-x))))</code> <br />
        Returns the sigmoid of each element.
    </td>
</tr>
<tr>
    <td>sin(t)</td>
    <td>
        <code>map(t, f(x)(sin(x)))</code> <br />
        Sinus of each element.
    </td>
</tr>
<tr>
    <td>sinh(t)</td>
    <td>
        <code>map(t, f(x)(sinh(x)))</code> <br />
        Hyperbolic sinus of each element.
    </td>
</tr>
<tr>
    <td>sign(t)</td>
    <td>
        <code>map(t, f(x)(if(x &lt; 0, -1.0, 1.0)))</code> <br />
        The sign of each element.
    </td>
</tr>
<tr>
    <td>softmax(t, dim)</td>
    <td>
        <code>join(map(t, f(x)(exp(x))), reduce(map(t, f(x)(exp(x))), sum, dim), f(x,y)(x / y))</code> <br />
        The softmax of the tensor, e.g. <code>e^x / sum(e^x)</code>.
    </td>
</tr>
<tr>
    <td>sqrt(t)</td>
    <td>
        <code>map(t, f(x)(sqrt(x)))</code> <br />
        The square root of each element.
    </td>
</tr>
<tr>
    <td>square(t)</td>
    <td>
        <code>map(t, f(x)(square(x)))</code> <br />
        The square of each element.
    </td>
</tr>
<tr>
    <td>t1 - t2 (subtract)</td>
    <td>
        <code>join(t1, t2, f(x,y)(x - y))</code> <br />
        Join and subtract tensors <code>t1</code> and <code>t2</code>.
    </td>
</tr>
<tr>
    <td>sum(t, dim)</td>
    <td>
        <code>reduce(t, sum, dim)</code> <br />
        Reduce the tensor with the <code>summation</code> aggregator along dimension <code>dim</code>.
    </td>
</tr>
<tr>
    <td>tan(t)</td>
    <td>
        <code>map(t, f(x)(tan(x)))</code> <br />
        The tangent of each element.
    </td>
</tr>
<tr>
    <td>tanh(t)</td>
    <td>
        <code>map(t, f(x)(tanh(x)))</code> <br />
        The hyperbolic tangent of each element.
    </td>
</tr>
<tr>
    <td>xw_plus_b(x,w,b,dim)</td>
    <td>
        <code>join(reduce(join(x, w, f(x,y)(x * y)), sum, dim), b, f(x,y)(x+y))</code> <br />
        Matrix multiplication of <code>x</code> (usually a vector) and <code>w</code> (weights), with <code>b</code> added (bias). A typical operation for activations in a neural network layer, e.g. <code>sigmoid(xw_plus_b(x,w,b)))</code>.
    </td>
</tr>


</tbody>
</table>


<h2>Tensor Rank Features</h2>
<p>
The following rank features can be used to reference tensors when doing tensor operations in ranking expressions.
The tensors can come from the document, the query or be constant for a deployment of your application.
</p>
<p>
Please take a look at the following reference documentations on how use tensors in documents:
<ul class="semicompact">
    <li><a href="search-definitions-reference.html#type:tensor">Tensor field in search definition</a></li>
    <li><a href="document-json-format.html">Document JSON Format</a></li>
</ul>
</p>


<h3>- attribute(tensor_attribute)</h3>
<p>
Returns the tensor value found in the given tensor attribute.
</p>

<p>
Take a look at <a href="search-definitions-reference.html#type:tensor">tensor type</a> and
<a href="#tensor-type-spec">tensor-type-spec</a>
reference doc for how to setup a tensor attribute in your search definition.
</p>

<p>Example tensor attribute field in a sd-file where the tensor has 2 mapped dimensions, <em>x</em> and <em>y</em>:</p>
<pre>
field tensor_attribute type tensor(x{},y{}) {
    indexing: attribute | summary
}
</pre>


<h3 id="query-feature">- query(tensor_feature)</h3>
<p>
Returns the tensor value passed down with the query as a feature.
</p>

<p>
In order to use this feature you must define the tensor type of the query feature in a query profile type.
In the following example the tensor type is defined to have one mapped dimension <em>x</em>:
<pre>
&lt;query-profile-type id="myProfileType"&gt;
  &lt;field name="ranking.features.query(tensor_feature)" type="tensor(x{})" /&gt;
&lt;/query-profile-type&gt;
</pre>

The tensor value itself must be set in a searcher using the com.yahoo.search.query.ranking.RankFeatures
instance that is associated with an instance of com.yahoo.search.Query.
In the following example we create a tensor with a single cell with value 500:
<pre>
package com.yahoo.example;

import com.yahoo.search.Query;
import com.yahoo.search.Result;
import com.yahoo.search.Searcher;
import com.yahoo.search.searchchain.Execution;
import com.yahoo.tensor.MappedTensor;
import com.yahoo.tensor.TensorType;

public class TensorInQuerySearcher extends Searcher {
    @Override
    public Result search(Query query, Execution execution) {
        query.getRanking().getFeatures().put("query(tensor_feature)",
            new MappedTensor.Builder(TensorType.fromSpec("tensor(x{})")).cell().label("x", "foo").value(500).build());
        return execution.search(query);
    }
}
</pre>

</p>

<p>
Take a look at <a href="query-profile-reference.html#field-type">query profile field type</a>
reference doc for more information on how to specify a field as a tensor in a query profile type.
</p>


<h3 id="constant-feature">- constant(tensor_constant)</h3>
<p>
Returns the constant tensor value with the given name as specified in your sd-file.
</p>

<p>
Take a look at <a href="search-definitions-reference.html#constant">constant</a> reference
documentation for how to specify constant tensors in your sd-file.
</p>


<h3 id="tensor-from-weighted-set-feature">- tensorFromWeightedSet(source, dimension)</h3>
<p>
Creates a tensor with one mapped dimension from the given integer or string weighted set source. The source can be either an attribute field or a query parameter.
The <em>source</em> parameter is required and must be specified as follows:
<ul class="semicompact">
    <li><em>attribute(attributeName)</em>: The tensor is created based on the content of the weighted set attribute <em>attributeName</em>.</li>
    <li><em>query(propertyName)</em>: The tensor is created based on the weighted set passed down with the query using
    <code>&amp;ranking.properties.propertyName={k1:w1,k2:w2,...,kN:wN}</code>.</li>
</ul>
The <em>dimension</em> parameter is optional, where the default value is the parameter name from the source parameter.
</p>

<p>
Example:<br>
Assume we have the following weighted set with keys and corresponding weights, and the dimension <em>dim</em>:
<pre>
{k1:w1,k2:w1,...,kN:wN}
</pre>
The tensor representation of this weighted set has the dimension <em>dim</em> with the following content:
<pre>
{ {dim:k1}:w1, {dim:k2}:w2, ..., {dim:kN}:wN} }
</pre>
</p>


<h3 id="tensor-from-labels-feature">- tensorFromLabels(source, dimension)</h3>
<p>
Creates a tensor with one mapped dimension from the given integer or string array source. The source can be either an attribute field or a query parameter.
The <em>source</em> parameter is required and must be specified as follows:
<ul class="semicompact">
    <li><em>attribute(attributeName)</em>: The tensor is created based on the content of the array attribute <em>attributeName</em>.</li>
    <li><em>query(propertyName)</em>: The tensor is created based on the array passed down with the query using
    <code>&amp;ranking.properties.propertyName=[v1 v2 ... vN]</code>.</li>
</ul>
The <em>dimension</em> parameter is optional, where the default value is the parameter name from the source parameter.
</p>

<p>
Example:<br>
Assume we have the following array with values and the dimension <code>dim</code>:
<pre>
[v1 v2 ... vN]
</pre>
The tensor representation of this array has the dimension <em>dim</em> with the following content:
<pre>
{ {dim:v1}:1.0, {dim:v2}:1.0, ..., {dim:vN}:1.0} }
</pre>
</p>


