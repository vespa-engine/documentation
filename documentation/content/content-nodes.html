---
# Copyright 2017 Yahoo Holdings. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root.
title: "Content nodes and states"
---

<p>
Refer to <a href="../operations/admin-procedures.html">administrative procedures</a>
for configuration and state monitoring / management.
</p><p>
Refer to <a href="../elastic-vespa.html#writing-documents">writing documents</a>
for an overview of the Document API flow.
Content cluster nodes are <em>distributor</em>, <em>content node</em> and <em>cluster controller</em>:
</p>
<img src="img/elastic-feed.svg" height="340" width="310"/>



<h2 id="node-state">Node state</h2>
<p>
Content and distributor nodes have state:
</p>
<table class="table">
<tr>
  <th>Up</th>
  <td>The node is up and available to keep buckets and serve requests.</td>
</tr><tr>
  <th>Down</th>
  <td>The node is not available, and can not be used.</td>
</tr><tr>
  <th>Initializing</th>
  <td>The node is starting up.
      It knows what buckets it stores data for, and may serve requests,
      but it does not know the metadata for all its buckets yet,
      such as checksums and document counts.
      The node is available for bucket placement.
  </td>
</tr><tr>
  <th>Stopping</th>
  <td>This node is stopping and is expected to be down soon.
      This state is typically only exposed to the cluster controller
      to tell why the node stopped.
      The cluster controller will expose the node as down
      or in maintenance mode for the rest of the cluster.
      This state is thus not seen by the distribution algorithm.
  </td>
</tr><tr>
  <th>Maintenance</th>
  <td>This node is temporarily unavailable.
      The node is available for bucket placement, redundancy is hence lower. <!-- ToDo rewrite -->
      Using this mode, new replicas of the documents stored on this node will not be created,
      allowing the node to be down with less of a performance impact on the rest of the cluster.
      This mode is typically used to mask a down state during controlled node restarts,
      or by an administrator that need to do some short maintenance work,
      like upgrading software or restart the node.
  </td>
</tr><tr>
  <th>Retired</th>
  <td>A retired node is available and serves requests.
      This state is used to remove nodes while keeping redundancy.
      Buckets are moved to other nodes (with low priority), until empty.
      Special considerations apply when using
      <a href="../elastic-vespa.html#grouped-distribution">grouped distribution</a>
      as buckets are not necessarily removed.
  </td>
</tr>
</table>
<p>
Distributor nodes start / transfer buckets quickly
and are hence not in <em>maintenance</em> or <em>retired</em>.
<!-- ToDo: it should not be possible to set a distributor in this mode, check -->
</p>



<h2 id="cluster-state">Cluster state</h2>
<p>
There are three kinds of state:
</p>
<table class="table">
<tr id="unit-state">
  <th>Unit state</th>
  <td>
  <p>
  The cluster controller fetches states from all nodes, called <em>unit states</em>.
  States reported from the nodes are either <em>initializing</em>, <em>up</em> or <em>stopping</em>.
  If the node can not be reached, a <em>down</em> state is assumed.
  </p><p>
  This means, the cluster controller detects failed nodes.
  The subsequent <em>generated states</em> will hence have nodes in <em>down</em>,
  and the <a href="idealstate.html">ideal state algorithm</a> will redistribute
  <a href="buckets.html">buckets</a> of documents.
  </p>
  </td>
</tr><tr id="user-state">
  <th>User state</th>
  <td>
  <p>
  <em>user state</em> must be one of
  <em>up</em>, <em>down</em>, <em>maintenance</em> or <em>retired</em>:
  <ul>
  <li>Retire a node from a cluster -
      use <em>retired</em> to move buckets to other nodes</li>
  <li>Short-lived maintenance work -
      use <em>maintenance</em> to avoid merging buckets to other nodes</li>
  <li>Fail a bad node. The cluster controller or an operator can set a node <em>down</em></li>
  </ul>
  Use tools for <a href="../operations/admin-procedures.html#cluster-state">user state management</a>.
  </p>
  </td>
</tr><tr id="generated-state">
  <th style="white-space: nowrap">Generated state</th>
  <td>
  <p>
  The cluster controller <em>generates</em> the cluster state
  from the <em>unit</em> and <em>user</em> states, over time.
  The generated state is called the <em>cluster state</em>.
  </p>
  </td>
</tr>
</table>
<p>
For new cluster states, the cluster state version is upped,
and the new cluster state is broadcasted to all nodes.
There is a minimum time between each cluster state change.
<!-- ToDo ref to config here -->
</p><p>
It is possible to set a minimum capacity for the cluster state to be <em>up</em>.
<!-- ToDo ref to config here -->
If a cluster has so many nodes unavailable that it is considered down,
the state of each nodes is irrelevant,
and thus new cluster states will not be created and broadcasted
before enough nodes are back for the cluster to come back up.
A cluster state indicating the entire cluster is down,
may thus have outdated data on the node level.
</p>
<!-- ToDo: An example cluster state string is useful here -->



<h2 id="cluster-controller">Cluster controller</h2>
<p>
The main task of the cluster controller is to maintain the <a href="#cluster-state">cluster state</a>.
This is done by <em>polling</em> nodes for state,
<em>generating</em> a cluster state,
which is then <em>broadcast</em> to all the content nodes in the cluster.
Note that clients do not interface with the cluster controller -
they get the cluster state from the distributors - <a href="#distributor">details</a>.
<table class="table">
<tr id="node-state-polling">
  <th>Node state polling</th>
  <td>
  <p>
  The cluster controller polls nodes, sending the current cluster state.
  If the cluster state is no longer correct, the node returns correct information immediately.
  If the state is correct, the request lingers on the node,
  such that the node can reply to it immediately if its state changes.
  After a while, the cluster controller will send a new state request to the node,
  even with one pending.
  This triggers a reply to the lingering request and makes the new one linger instead.
  Hence, nodes have a pending state request.
  </p><p>
  During a controlled node shutdown, it starts the shutdown process
  by responding to the pending state request that it is now stopping.
  <strong>Note: </strong> As controlled restarts or shutdowns are implemented as TERM signals
  from the <a href="../config-sentinel.html">config-sentinel</a>,
  the cluster controller is not able to differ between controlled and other shutdowns.
  </p>
  </td>
</tr><tr id="cluster-state-generation">
  <th>Cluster state generation</th>
  <td>
  <p>
  The cluster controller translates unit and user states
  into the generated <em>cluster state</em>
  </p>
  </td>
</tr><tr id="state-broadcast">
  <th>Cluster state broadcast</th>
  <td>
  <p>
  When node unit states are received, a cluster controller internal cluster state is updated.
  New cluster states are distributed with a minimum interval between. <!-- ToDo link to config here -->
  A grace period per unit state too -
  e.g, distributors and content nodes that are on the same node often stop at the same time.
  </p><p>
  The version number is upped, and the new cluster state is broadcast.
  </p><p>
  If cluster state version is <a href="../operations/admin-procedures.html#cluster-state">reset</a>,
  clients to distributors can temporarily fail operations in the transition,
  but will eventually converge on the new (lower) cluster state version.
  </p>
  </td>
</tr>
</table>
</p>


<h3 id="master-election">Master election</h3>
<p>
Vespa can be configured with one cluster controller.
Reads and writes will work well in case of cluster controller down,
but other changes to the cluster (like a content node down) will not be handled.
It is hence recommended to configure a set of cluster controllers.
</p><p>
The cluster controller nodes elect a master,
which does the node polling and cluster state broadcast.
The other cluster controller nodes only exist to do master election
and potentially take over if the master dies.
</p><p>
All cluster controllers will vote for cluster controller with the lowest index that says it is ready.
If a cluster controller has more than half of the votes, it will be elected master.
As a majority vote is required,
the number of cluster controllers should be an odd number of 3 or greater.
A fresh master will not broadcast states before a transition time is passed, <!-- ToDo config ref -->
allowing an old master to have some time to realize it is no longer the master.
</p>



<h2 id="distributor">Distributor</h2>
<p>
Document operations are mapped to content nodes based on bucket locations -
each put/update/get/remove is mapped to a <a href="buckets.html">bucket</a>
and sent to the right content nodes.
To manage the document set as it grows and nodes change, buckets move.
I.e, sets of documents (a bucket) is copied between nodes for redundancy /
redistribution for growth / node failures.
</p><p>
Buckets are mapped to distributors using the <a href="idealstate.html">ideal state algorithm</a>.
As the cluster state changes, buckets are re-mapped immediately.
The mapping does not overlap - a bucket is owned by one distributor.
</p><p>
Distributors do not persist the bucket database,
the bucket-to-content-node mapping is stored in memory in the distributor.
Document count, persisted size and a metadata checksum per bucket is stored as well.
At distributor (re)start, content nodes are polled for bucket information,
and return which buckets are owned by this distributor (using the ideal state algorithm).
There is hence no master / name node in Vespa.
Likewise, at any distributor cluster state change,
content nodes are polled for bucket handover -
a distributor will then handle a new set of buckets.
</p><p>
Document API clients do not interface with the cluster controller,
and does hence not know the cluster start at startup.
A random distributor is used first.
If the document operation hit the wrong distributor,
<em>WRONG_DISTRIBUTION</em> is returned, with the current cluster state.
<em>WRONG_DISTRIBUTION</em> is hence expected and normal at cold start / state change events.
</p><p>
</p><p>
</p>


<h3 id="maintenance-operations">Maintenance operations</h3>
<p>
Distributors track which content nodes have which buckets in their bucket batabase.
Distributors then use the <a href="idealstate.html">ideal state algorithm</a>
to generate bucket <em>maintenance operations</em>.
A stable system has all buckets located per the ideal state:
<ul>
  <li>If buckets have too few replicas, new are generated on other content nodes.</li>
  <li>If the replicas differ, a bucket merge is issued to get replicas consistent.</li>
  <li>If a buckets has too many replicas, superfluous are deleted.
      Buckets are merged, if inconsistent, before deletion.</li>
  <li>If two buckets exist, such that both may contain the same document,
      the buckets are split or joined to remove such overlapping buckets.
      Read more on <a href="buckets.html">inconsistent buckets</a>.</li> <!-- ToDo: change this to a proper anchor within buckets.html - this needs a dedicated section, relevant to point to from visiting -->
  <li>If buckets are too small/large, they will be joined or split.</li>
  <li>In clusters a with document type marked as
      <a href="../reference/services-content.html#document">mode="index"</a>,
      the distributor will ensure that only one of a bucket's replicas within a group
      will be used when processing search queries.
      Otherwise search results would contain duplicates.
      This is known as an <a href="../proton.html#sub-databases">active</a> replica,
      the rest being <em>inactive</em> and available for failover
      if the currently active node should become unavailable,
      or the ideal state changes.</li>
</ul>
The maintenance operations have different priorities.
If no maintenance operations are needed, the cluster is said to be in the <em>ideal state</em>.
The distributors synchronize maintenance load with user load,
e.g. to remap requests to other buckets after bucket splitting and joining.
</p>


<h3 id="ordering">Ordering</h3>
<p>
The Document API uses the document identifier to implement ordering.
Documents with the same identifier will have the same serialize id,
and a Document API client will ensure that only one operation with a given
serialize id is pending at the same time.
This ensures that if a client sends multiple operations for the
same document, they will be processed in a defined order.
</p><p>
<strong>Note:</strong> If sending two <em>put</em> operations to the same
document, and the first operation fails, the second operation that was
enqueued is sent. If the client chooses to just resend the failed request,
the order of operations has been switched.
</p><p>
If <em>different</em> clients have pending operations on the same document,
the order is undefined.
</p>


<h3 id="timestamps">Timestamps</h3>
<p>
Write operations like <em>put</em>, <em>update</em> and <em>remove</em>,
have a timestamp assigned, passing through the distributor.
The timestamp is guaranteed to be unique within the
<a href="buckets.html">bucket</a> where it is stored.
The timestamp is used by the content layer to decide which operation is newest.
These timestamps may be used when <a href="visiting.html">visiting</a>,
to only process/retrieve documents within a given timeframe.
To guarantee unique timestamps, they are in microseconds,
and the microsecond part may be generated or altered to avoid conflicts with other documents.
</p><p>
The internal timestamp is often referred to as the last modified time.
This is the time of the last write operation going through the distributor.
If documents are migrated from cluster to cluster,
the target cluster will have new timestamps for their entries,
and when reprocessing documents within a cluster,
documents will have new timestamps even if not modified.
</p>
